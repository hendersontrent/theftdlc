[{"path":"https://hendersontrent.github.io/theftdlc/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 Trent Henderson Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"purpose","dir":"Articles","previous_headings":"","what":"Purpose","title":"Introduction to theftdlc","text":"theft package R facilitates user-friendly access structured analytical workflow extraction time-series features six different feature sets (number individual user-supplied features): \"catch22\", \"feasts\", \"kats\", \"tsfeatures\", \"tsfresh\", \"tsfel\". theftdlc extends feature-based ecosystem providing suite functions analysing, interpreting, visualising time-series features calculated using theft.","code":""},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"core-calculation-functions","dir":"Articles","previous_headings":"","what":"Core calculation functions","title":"Introduction to theftdlc","text":"explore package functionality, going use dataset comes standard theft called simData. dataset tsibble contains collection randomly generated time series six different types processes. dataset can accessed via: data follows following structure: use theft quickly calculate features using catch22 set:","code":"theft::simData head(simData) #> # A tsibble: 6 x 4 [1] #> # Key:       id, process [1] #>     values timepoint id      process #>      <dbl>     <int> <chr>   <chr>   #> 1  0.0918          1 AR(1)_1 AR(1)   #> 2  0.00617         2 AR(1)_1 AR(1)   #> 3  0.154           3 AR(1)_1 AR(1)   #> 4  0.100           4 AR(1)_1 AR(1)   #> 5 -0.0219          5 AR(1)_1 AR(1)   #> 6 -0.230           6 AR(1)_1 AR(1) feature_matrix <- calculate_features(data = simData,                                       feature_set = \"catch22\")"},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"data-quality-checks","dir":"Articles","previous_headings":"","what":"Data quality checks","title":"Introduction to theftdlc","text":"core calculate_features function theft returns object class feature_calculations. Objects type purposefully looked-functions theftdlc. class, simple methods plot() can called object produce range statistical graphics. first visualisation data types calculated feature vectors. useful inspecting features might need dropped due large proportions undesirable (e.g., NA, NaN etc.) values. can specify plot type = \"quality make graphic:","code":"plot(feature_matrix, type = \"quality\")"},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"data-visualisation-and-low-dimensional-projections","dir":"Articles","previous_headings":"","what":"Data visualisation and low-dimensional projections","title":"Introduction to theftdlc","text":"package also comes additional statistical graphical functionality: Feature time-series matrix heatmap Low dimensional projections feature space plotting scatterplot Pairwise feature correlation matrix heatmap","code":""},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"feature-matrices","dir":"Articles","previous_headings":"Data visualisation and low-dimensional projections","what":"Feature matrices","title":"Introduction to theftdlc","text":"function calling type = \"matrix\" plot() feature_calculations object takes produces ggplot object heatmap showing feature vectors across x axis time series y axis. Prior plotting, function hierarchically clusters data across rows columns visually highlight empirical structure. Note several options hierarchical clustering linkage algorithm use: \"average\" (default) \"ward.D\" \"ward.D2\" \"single\" \"complete\" \"mcquitty\" \"median\" \"centroid\" See hclust documentation information. Note legend plot (matrix visualisations theftdlc) discretised visual clarity continuous legends can difficult interpret meaningful value differences easily.  can control normalisation type norm_method argument, whether rescale unit interval normalisation unit_int argument. norm_method normalisation feature vectors theftdlc handled normaliseR package. can also control hierarchical clustering method clust_method argument (example used defaults manual specification needed).","code":"plot(feature_matrix, type = \"matrix\", norm_method = \"RobustSigmoid\")"},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"individual-feature-distributions","dir":"Articles","previous_headings":"Data visualisation and low-dimensional projections","what":"Individual feature distributions","title":"Introduction to theftdlc","text":"Plotting entire feature matrix useful, sometimes wish understand distributions individual features. particularly useful different groups data (time-series classification context). can use plot() generic draw violin plots setting type = \"violin\". Note violin plots, also need tell function features wish plot (.e., vector characters specifying feature names names column feature_calculations object). simplicity, just plot two random features catch22 :  Note using defined plot() generics, can pass additional arguments certain geoms control plot look ... argument plot() function. guide arguments go depending plot type: type = \"quality\"—... goes ggplot2::geom_bar type = \"matrix\"—... goes ggplot2::geom_raster type = \"cor\"—... goes ggplot2::geom_raster type = \"violin\"—... goes ggplot2::geom_point example, may wish control point size transparency plot (rendered space):","code":"plot(feature_matrix, type = \"violin\",      feature_names = c(\"CO_f1ecac\", \"PD_PeriodicityWang_th0_01\")) plot(feature_matrix, type = \"violin\",      feature_names = c(\"CO_f1ecac\", \"PD_PeriodicityWang_th0_01\"),      size = 0.7, alpha = 0.9)"},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"low-dimensional-projections","dir":"Articles","previous_headings":"Data visualisation and low-dimensional projections","what":"Low dimensional projections","title":"Introduction to theftdlc","text":"Low-dimensional projections useful tool visualising structure high-dimensional datasets low-dimensional spaces. machine learning time-series data, often interested representing time-series dataset two-dimensional projection high-dimensional feature space. projection can reveal structure dataset, including different labeled classes organized. theftdlc function project takes feature_calculations object performs one following dimension reduction techniques reduce dimensionality bivariate state can easily plotted: Principal components analysis (PCA)—\"PCA\" tt-Stochastic Neighbor Embedding (tt-SNE)—\"tSNE\" Classical multidimensional scaling (MDS)—\"ClassicalMDS\" Kruskal’s non-metric multidimensional scaling—\"KruskalMDS\" Sammon’s non-linear mapping non-metric multidimensional scaling—\"SammonMDS\" Uniform Manifold Approximation Projection Dimension Reduction (UMAP)—\"UMAP\" result stored custom object class called feature_projection. project takes following arguments: data—feature_calculations object containing raw feature matrix produced theft::calculate_features norm_method—character denoting rescaling/normalising method apply. Can one \"zScore\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\", \"MaxAbs\". Defaults \"zScore\" unit_int—Boolean whether rescale unit interval [0,1][0,1] applying normalisation method. Defaults FALSE low_dim_method—character specifying low dimensional embedding method use. Can one \"PCA\" \"tSNE\", \"ClassicalMDS\", \"KruskalMDS\", \"SammonMDS\", \"UMAP\". Defaults \"PCA\" na_removal—character defining way deal NAs produced feature calculation. Can one \"feature\" \"sample\". \"feature\" removes features produced NAs sample, keeping number samples . \"sample\" omits samples produced least one NA. Defaults \"feature\" seed—integer fix R’s random number generator ensure reproducibility. Defaults 123 ... arguments passed respective function specified low_dim_method project returns object class feature_projection essentially named list comprised four elements: \"Data\"—feature_calculations object supplied project \"ModelData\"—wide matrix filtered data supplied model fit \"ProjectedData\"—tidy data.frame two-dimensional embedding \"ModelFit\"—raw model object dimensionality reduction algorithm can similarly call plot() object produce two-dimensional scatterplot results:  another example, t-SNE version can specified similar fashion, function parameters method supplied ... argument project. Shaded covariance ellipses can also disabled plotting feature_projection objects setting show_covariance = FALSE. example modify perplexity t-SNE algorithm:","code":"low_dim <- project(feature_matrix,                    norm_method = \"RobustSigmoid\",                    unit_int = TRUE,                    low_dim_method = \"PCA\",                    seed = 123) plot(low_dim) low_dim2 <- project(feature_matrix,                     norm_method = \"RobustSigmoid\",                     unit_int = TRUE,                     low_dim_method = \"tSNE\",                     perplexity = 10,                     seed = 123)  plot(low_dim2, show_covariance = FALSE)"},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"pairwise-correlations","dir":"Articles","previous_headings":"Data visualisation and low-dimensional projections","what":"Pairwise correlations","title":"Introduction to theftdlc","text":"can plot correlations feature vectors using plot(type = \"cor\") feature_calculations object:  Similarly, can control normalisation type norm_method argument hierarchical clustering method clust_method argument (example used defaults manual specification needed).","code":"plot(feature_matrix, type = \"cor\")"},{"path":[]},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"feature-by-feature","dir":"Articles","previous_headings":"Time-series classification","what":"Feature-by-feature","title":"Introduction to theftdlc","text":"Since feature-based time-series analysis shown particular promise classification problems, theftdlc includes functionality exploring group separation. function classify enables fit range classification models enable statistical comparisons using resampling methodology presented paper detailed review1. function meant serve fast answer can used guide analysis replacement development careful statistical pipeline. classify following arguments: data—feature_calculations object containing raw feature matrix produced theft::calculate_features included group column per theft::calculate_features classifier—function specifying classifier fit. function 2 arguments: formula data. Please note classify z-scores data prior modelling using train set’s information disabling default scaling function uses recommended. Defaults NULL means following linear SVM fit: classifier = function(formula, data){mod <- e1071::svm(formula, data = data, kernel = \"linear\", scale = FALSE, probability = TRUE)} train_size—Numeric value denoting proportion samples use training set. Defaults 0.75 n_resamples—Integer denoting number resamples calculate. Defaults 30 by_set—Boolean specifying whether compute classifiers feature set. Defaults TRUE (see section “Multi-feature” ). FALSE, function instead find best individually-performing features use_null—Boolean whether fit null models class labels shuffled order generate null distribution can compared performance correct class labels. Defaults FALSE. known permutation testing seed—Integer fix R’s random number generator ensure reproducibility. Defaults 123 Since interested individual features section, calculate main null results feature using just 5 resamples efficiency (practice, use !) default linear SVM: show simple specify different classifier, can instead maybe use radial basis function SVM (though absolutely limited just e1071 models! can use anything can used R’s predict generic classify internally constructs confusion matrices model predictions): raw classification results useful, often also like statistical evaluate facet . theftdlc includes function compare_features . compare_features contains following arguments: data—List object containing classification outputs produce classify metric—Character denoting classification performance metric use statistical testing. Can one \"accuracy\", \"precision\", \"recall\", \"f1\". Defaults \"accuracy\" by_set—Boolean specifying whether want compare feature sets (TRUE) individual features (FALSE). Defaults TRUE contingent whether computed set classify hypothesis—Character denoting whether p-values calculated feature set feature (depending by_set argument) individually relative null use_null = TRUE classify \"null\", whether pairwise comparisons set feature conducted main model fits \"pairwise\". Defaults \"null\" p_adj—Character denoting adjustment made p-values multiple comparisons. valid argument stats::p.adjust. Defaults \"none\" adjustment. \"holm\" recommended starting point adjustments sought can use compare_features evaluate well individual feature performs relative empirical null distribution (noting using defaults arguments code cleanliness): conduct pairwise comparisons individual features: can use ggplot2 summarise visualise results. pairwise correlation plot top 10 features catch22 toy problem. just simply filtering original full feature data making use plot generic defined objects class feature_calculations:  can also easily draw violin plot top 10 features visualise distributions group:  theftdlc also contains function interval summarising results classify. interval returns object class interval_calculations data frame containing summary information. interval takes following arguments: data—list object containing classification outputs produce classify metric—character denoting classification performance metric calculate intervals . Can one \"accuracy\", \"precision\", \"recall\", \"f1\". Defaults \"accuracy\" by_set—Boolean specifying whether compute intervals feature set. Defaults TRUE. FALSE, function instead calculate intervals feature type—character denoting whether calculate ±\\pm SD interval \"sd\", confidence interval based tt-distribution \"qt\", based quantile \"quantile\". Defaults \"sd\" interval—numeric scalar denoting width interval calculate. Defaults 1 type = \"sd\" produce ±1\\pm 1 SD interval. Defaults 0.95 type = \"qt\" type = \"quantile\" 95%95\\% interval model_type—character denoting whether calculate intervals main models \"main\" null models \"null\" use_null argument using classify use_null = TRUE. Defaults \"main\" can evidently use interval produce variety different summaries us. example, might wish compute ±1\\pm1 SD interval feature’s main model classification accuracy values (note defaults function us, need set by_set = FALSE manually):","code":"feature_classifiers <- classify(feature_matrix,                                 by_set = FALSE,                                 n_resamples = 5,                                 use_null = TRUE) myclassifier <- function(formula, data){   mod <- e1071::svm(formula, data = data, kernel = \"radial\", scale = FALSE,                     probability = TRUE) }  feature_classifiers_radial <- classify(feature_matrix,                                        classifier = myclassifier,                                        by_set = FALSE,                                        n_resamples = 5,                                        use_null = TRUE) feature_vs_null <- compare_features(feature_classifiers,                                     by_set = FALSE,                                     hypothesis = \"null\")  head(feature_vs_null) #>                                                 hypothesis #> 1 catch22_CO_Embed2_Dist_tau_d_expfit_meandiff != own null #> 2                            catch22_CO_f1ecac != own null #> 3                       catch22_CO_FirstMin_ac != own null #> 4             catch22_CO_HistogramAMI_even_2_5 != own null #> 5                        catch22_CO_trev_1_num != own null #> 6                  catch22_DN_HistogramMode_10 != own null #>                                          names #> 1 catch22_CO_Embed2_Dist_tau_d_expfit_meandiff #> 2                            catch22_CO_f1ecac #> 3                       catch22_CO_FirstMin_ac #> 4             catch22_CO_HistogramAMI_even_2_5 #> 5                        catch22_CO_trev_1_num #> 6                  catch22_DN_HistogramMode_10 #>                         original_names feature_set   metric feature_mean #> 1 CO_Embed2_Dist_tau_d_expfit_meandiff     catch22 accuracy    0.3333333 #> 2                            CO_f1ecac     catch22 accuracy    0.3555556 #> 3                       CO_FirstMin_ac     catch22 accuracy    0.3022222 #> 4             CO_HistogramAMI_even_2_5     catch22 accuracy    0.3688889 #> 5                        CO_trev_1_num     catch22 accuracy    0.1377778 #> 6                  DN_HistogramMode_10     catch22 accuracy    0.0800000 #>    null_mean t_statistic    p.value #> 1 0.05777778   4.7002079 0.00930697 #> 2 0.06222222          NA         NA #> 3 0.11111111   1.8874905 0.13213287 #> 4 0.07111111   2.4319459 0.07182989 #> 5 0.07555556   1.7232809 0.15993480 #> 6 0.10222222  -0.3892495 0.71692586 pairwise_features <- compare_features(feature_classifiers,                                       by_set = FALSE,                                       hypothesis = \"pairwise\",                                       p_adj = \"holm\")  head(pairwise_features) #>                                                                         hypothesis #> 1                catch22_CO_Embed2_Dist_tau_d_expfit_meandiff != catch22_CO_f1ecac #> 2           catch22_CO_Embed2_Dist_tau_d_expfit_meandiff != catch22_CO_FirstMin_ac #> 3 catch22_CO_Embed2_Dist_tau_d_expfit_meandiff != catch22_CO_HistogramAMI_even_2_5 #> 4            catch22_CO_Embed2_Dist_tau_d_expfit_meandiff != catch22_CO_trev_1_num #> 5      catch22_CO_Embed2_Dist_tau_d_expfit_meandiff != catch22_DN_HistogramMode_10 #> 6       catch22_CO_Embed2_Dist_tau_d_expfit_meandiff != catch22_DN_HistogramMode_5 #>                                        names_a                          names_b #> 1 catch22_CO_Embed2_Dist_tau_d_expfit_meandiff                catch22_CO_f1ecac #> 2 catch22_CO_Embed2_Dist_tau_d_expfit_meandiff           catch22_CO_FirstMin_ac #> 3 catch22_CO_Embed2_Dist_tau_d_expfit_meandiff catch22_CO_HistogramAMI_even_2_5 #> 4 catch22_CO_Embed2_Dist_tau_d_expfit_meandiff            catch22_CO_trev_1_num #> 5 catch22_CO_Embed2_Dist_tau_d_expfit_meandiff      catch22_DN_HistogramMode_10 #> 6 catch22_CO_Embed2_Dist_tau_d_expfit_meandiff       catch22_DN_HistogramMode_5 #>     metric names_a_mean names_b_mean t_statistic    p.value p_value_adj #> 1 accuracy    0.3333333    0.3555556          NA         NA          NA #> 2 accuracy    0.3333333    0.3022222   0.9525793 0.39474545   1.0000000 #> 3 accuracy    0.3333333    0.3688889  -0.5819144 0.59184415   1.0000000 #> 4 accuracy    0.3333333    0.1377778   4.4907312 0.01089970   1.0000000 #> 5 accuracy    0.3333333    0.0800000   5.7287155 0.00459701   0.7768946 #> 6 accuracy    0.3333333    0.1022222   4.8702462 0.00821823   1.0000000 top_10 <- feature_vs_null %>%   dplyr::slice_min(p.value, n = 10) %>%   dplyr::select(c(feature_set, original_names, p.value))  feature_matrix_filt <- feature_matrix %>%   dplyr::filter(feature_set %in% top_10$feature_set & names %in% top_10$original_names)  feature_matrix_filt <- structure(feature_matrix_filt, class = c(\"feature_calculations\", \"data.frame\")) plot(feature_matrix_filt, type = \"cor\") plot(feature_matrix_filt,      type = \"violin\",      feature_names = top_10$original_names) interval(feature_classifiers, by_set = FALSE) #>                                                  names      .mean     .lower #> 1         catch22_CO_Embed2_Dist_tau_d_expfit_meandiff 0.33333333 0.31111111 #> 2                                    catch22_CO_f1ecac 0.35555556 0.35555556 #> 3                               catch22_CO_FirstMin_ac 0.30222222 0.26185355 #> 4                     catch22_CO_HistogramAMI_even_2_5 0.36888889 0.32852022 #> 5                                catch22_CO_trev_1_num 0.13777778 0.11343455 #> 6                          catch22_DN_HistogramMode_10 0.08000000 0.05018576 #> 7                           catch22_DN_HistogramMode_5 0.10222222 0.04427376 #> 8                catch22_DN_OutlierInclude_n_001_mdrmd 0.08888889 0.07317540 #> 9                catch22_DN_OutlierInclude_p_001_mdrmd 0.09777778 0.07244055 #> 10              catch22_FC_LocalSimple_mean1_tauresrat 0.46222222 0.39858746 #> 11                 catch22_FC_LocalSimple_mean3_stderr 0.56444444 0.53910721 #> 12     catch22_IN_AutoMutualInfoStats_40_gaussian_fmmi 0.19111111 0.15740944 #> 13                        catch22_MD_hrv_classic_pnn40 0.21777778 0.17503248 #> 14                   catch22_PD_PeriodicityWang_th0_01 0.25777778 0.22059289 #> 15            catch22_SB_BinaryStats_diff_longstretch0 0.21777778 0.15814930 #> 16            catch22_SB_BinaryStats_mean_longstretch1 0.29333333 0.27474089 #> 17                   catch22_SB_MotifThree_quantile_hh 0.40000000 0.35030960 #> 18          catch22_SB_TransitionMatrix_3ac_sumdiagcov 0.24444444 0.22873096 #> 19      catch22_SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1 0.11111111 0.06397066 #> 20 catch22_SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1 0.13777778 0.10126294 #> 21            catch22_SP_Summaries_welch_rect_area_5_1 0.68888889 0.65039887 #> 22            catch22_SP_Summaries_welch_rect_centroid 0.45777778 0.39185601 #>       .upper #> 1  0.3555556 #> 2  0.3555556 #> 3  0.3425909 #> 4  0.4092576 #> 5  0.1621210 #> 6  0.1098142 #> 7  0.1601707 #> 8  0.1046024 #> 9  0.1231150 #> 10 0.5258570 #> 11 0.5897817 #> 12 0.2248128 #> 13 0.2605231 #> 14 0.2949627 #> 15 0.2774063 #> 16 0.3119258 #> 17 0.4496904 #> 18 0.2601579 #> 19 0.1582516 #> 20 0.1742926 #> 21 0.7273789 #> 22 0.5236995"},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"multi-feature","dir":"Articles","previous_headings":"Time-series classification","what":"Multi-feature","title":"Introduction to theftdlc","text":"Since theft contains entire sets features, can also use classify compare set level by_set argument. Let’s try catch22 custom set just mean standard deviation: Note classify constructs set \"features\" (.e., features across computed sets) automatically >2>2 unique feature sets detected feature data. Since interval returns S3 object, can use plot generic automatically draw useful visual summary:","code":"feature_matrix2 <- calculate_features(data = simData,                                        feature_set = \"catch22\",                                       features = list(\"mean\" = mean, \"sd\" = sd),                                       seed = 123)  set_classifiers <- classify(feature_matrix2,                             by_set = TRUE,                             n_resamples = 5,                             use_null = TRUE)  head(set_classifiers) #> $TrainTestSizes #> train_size  test_size  #>        135         45  #>  #> $ClassificationResults #>    model_type resample   accuracy mean_precision mean_recall mean_f1_score #> 1        Main        1 0.84444444     0.86574074  0.88827839     0.8682359 #> 2        Main        2 0.91111111     0.92592593  0.92592593     0.9259259 #> 3        Main        3 0.75555556     0.79166667  0.81649832     0.8002646 #> 4        Main        4 0.77777778     0.81018519  0.81693122     0.8126706 #> 5        Main        5 0.80000000     0.83333333  0.83333333     0.8328173 #> 6        Null        1 0.13333333     0.19490741  0.11458333     0.1980420 #> 7        Null        2 0.13333333     0.14709596  0.17216811     0.1527193 #> 8        Null        3 0.08888889     0.08888889  0.11309524     0.2986111 #> 9        Null        4 0.33333333     0.36582492  0.36984127     0.3244168 #> 10       Null        5 0.13333333     0.10332492  0.16730769     0.2411616 #> 11       Main        1 0.82222222     0.85185185  0.85281385     0.8500000 #> 12       Main        2 0.77777778     0.81481481  0.81481481     0.8148148 #> 13       Main        3 0.75555556     0.79629630  0.79583333     0.7956656 #> 14       Main        4 0.82222222     0.85185185  0.85281385     0.8500000 #> 15       Main        5 0.80000000     0.83333333  0.83333333     0.8285714 #> 16       Null        1 0.11111111     0.16666667  0.23809524     0.8333333 #> 17       Null        2 0.26666667     0.33333333  0.30912162     0.4683794 #> 18       Null        3 0.08888889     0.13333333  0.20000000     0.8000000 #> 19       Null        4 0.11111111     0.16666667  0.31250000     0.7692308 #> 20       Null        5 0.02222222     0.05555556  0.05555556     0.2222222 #> 21       Main        1 0.77777778     0.79537037  0.78860029     0.7878788 #> 22       Main        2 0.82222222     0.84953704  0.83201058     0.8373812 #> 23       Main        3 0.66666667     0.68564815  0.71801347     0.6931883 #> 24       Main        4 0.71111111     0.75462963  0.73547980     0.7180744 #> 25       Main        5 0.77777778     0.80000000  0.79814815     0.7901961 #> 26       Null        1 0.13333333     0.15787037  0.11428571     0.2346154 #> 27       Null        2 0.08888889     0.07302189  0.11666667     0.1300595 #> 28       Null        3 0.11111111     0.10740741  0.15714286     0.2511905 #> 29       Null        4 0.26666667     0.24936869  0.27910053     0.2931502 #> 30       Null        5 0.08888889     0.06965488  0.12777778     0.1790598 #>     feature_set #> 1  All features #> 2  All features #> 3  All features #> 4  All features #> 5  All features #> 6  All features #> 7  All features #> 8  All features #> 9  All features #> 10 All features #> 11         User #> 12         User #> 13         User #> 14         User #> 15         User #> 16         User #> 17         User #> 18         User #> 19         User #> 20         User #> 21      catch22 #> 22      catch22 #> 23      catch22 #> 24      catch22 #> 25      catch22 #> 26      catch22 #> 27      catch22 #> 28      catch22 #> 29      catch22 #> 30      catch22 interval_calcs <- interval(set_classifiers)  plot(interval_calcs)"},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"cluster-analysis","dir":"Articles","previous_headings":"","what":"Cluster analysis","title":"Introduction to theftdlc","text":"theftdlc also supports quick simple cluster analysis using either kk-means, hierarchical clustering, Gaussian mixture models cluster function. cluster takes similar key arguments theftdlc functions (though defaults set , data required cluster work): data—feature_calculations object containing raw feature matrix produced theft::calculate_features norm_method—character denoting rescaling/normalising method apply. Can one \"zScore\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\", \"MaxAbs\". Defaults \"zScore\" unit_int—Boolean whether rescale unit interval [0,1][0,1] applying normalisation method. Defaults FALSE clust_method—character specifying clustering algorithm use. Can one \"kmeans\", \"hclust\", \"mclust\". Defaults \"kmeans\" k—integer denoting number clusters extract. Defaults 2 features—character vector denoting names time-series features use clustering algorithm. Defaults NULL feature filtering usage entire feature matrix na_removal—character defining way deal NAs produced feature calculation. Can one \"feature\" \"sample\". \"feature\" removes features produced NAs sample, keeping number samples . \"sample\" omits samples produced least one NA. Defaults \"feature\" seed—integer fix R’s random number generator ensure reproducibility. Defaults 123 ...—additional arguments passed stats::kmeans, stats::hclust, mclust::Mclust depending clust_method cluster returns object class feature_clusters essentially named list comprised two elements: \"Data\"—feature_calculations object supplied cluster cluster label appended \"ModelFit\"—raw model object clustering algorithm can easily fit kk-means model k = 6 (since theft::simData contains data six different temporal processes): , ’s easy analysis data visualisation:","code":"feature_clusters <- cluster(feature_matrix, k = 6) feature_clusters$Data %>%     dplyr::filter(names %in% c(\"CO_HistogramAMI_even_2_5\",                                 \"DN_OutlierInclude_p_001_mdrmd\")) %>%     tidyr::pivot_wider(id_cols = c(\"id\", \"group\", \"cluster\"),                         names_from = \"names\", values_from = \"values\") %>%     ggplot2::ggplot(ggplot2::aes(x = CO_HistogramAMI_even_2_5,                                   DN_OutlierInclude_p_001_mdrmd,                                   colour = as.factor(cluster))) +     ggplot2::stat_ellipse(ggplot2::aes(fill = as.factor(cluster)), geom = \"polygon\", alpha = 0.2) +     ggplot2::geom_point() +     ggplot2::labs(colour = \"Cluster\") +     ggplot2::guides(fill = \"none\") +     ggplot2::scale_fill_brewer(palette = \"Dark2\") +     ggplot2::scale_colour_brewer(palette = \"Dark2\") +     ggplot2::theme_bw() +     ggplot2::theme(legend.position = \"bottom\",                    panel.grid.minor = ggplot2::element_blank())"},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"feature-selection","dir":"Articles","previous_headings":"","what":"Feature selection","title":"Introduction to theftdlc","text":"Feature selection well-studied field, selection approach given problem carefully considered. theftdlc offers simple option users seeking fast answers shrink function, implements cross-validated penalised maximum likelihood generalized linear model glmnet package. Since theftdlc largely concerned time-series classification, currently possible calculate_features group column. Specifically, binomial case, shrink finds time-series features whose coefficients non-zero, multinomial case (.e., >2>2 groups) shrink finds time-series features non-zero across group distinctions. shrink takes four arguments returns feature_calculations object can used theftdlc, just like calculate_features: data — feature_calculations object threshold — applies multinomial (.e., multiclass) classification problems . Determines whether retain features least one non-zero coefficient across different classes (threshold = \"one\") features non-zero coefficients across classes (threshold = \"\"). Defaults \"one\" less aggressive filtering plot — whether plot misclassification error lambda plot CV model. Defaults FALSE ... — additional arguments passed glmnet::cv.glmnet control model fitting process  can compare number features original set reduced feature set: see selection process retained 44 features. Note process far useful higher dimensional cases, features six sets theft calculated.","code":"feature_matrix_red <- shrink(feature_matrix, plot = TRUE) length(unique(feature_matrix$names)) #> [1] 22 length(unique(feature_matrix_red$names)) #> [1] 4"},{"path":"https://hendersontrent.github.io/theftdlc/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Trent Henderson. Maintainer, author.","code":""},{"path":"https://hendersontrent.github.io/theftdlc/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Henderson T (2025). theftdlc: Analyse Interpret Time Series Features. R package version 0.1.3, https://hendersontrent.github.io/theftdlc/.","code":"@Manual{,   title = {theftdlc: Analyse and Interpret Time Series Features},   author = {Trent Henderson},   year = {2025},   note = {R package version 0.1.3},   url = {https://hendersontrent.github.io/theftdlc/}, }"},{"path":"https://hendersontrent.github.io/theftdlc/index.html","id":"theftdlc-","dir":"","previous_headings":"","what":"Analyse and Interpret Time Series Features","title":"Analyse and Interpret Time Series Features","text":"Analyse Interpret Time Series Features","code":""},{"path":"https://hendersontrent.github.io/theftdlc/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Analyse and Interpret Time Series Features","text":"can install stable version theftdlc CRAN: can install development version theftdlc GitHub using following:","code":"install.packages(\"theftdlc\") devtools::install_github(\"hendersontrent/theftdlc\")"},{"path":"https://hendersontrent.github.io/theftdlc/index.html","id":"general-purpose","dir":"","previous_headings":"","what":"General purpose","title":"Analyse and Interpret Time Series Features","text":"theft package R facilitates user-friendly access structured analytical workflow extraction time-series features six different feature sets (number individual user-supplied features): \"catch22\", \"feasts\", \"kats\", \"tsfeatures\", \"tsfresh\", \"tsfel\". theftdlc extends feature-based ecosystem providing suite functions analysing, interpreting, visualising time-series features calculated using theft. Functionality including data quality assessments normalisation methods, low dimensional projections (linear nonlinear), data matrix feature distribution visualisations, time-series classification machine learning procedures, statistical hypothesis testing, various statistical graphical tools.  high-level overview theft ecosystem R typically accessed users shown . Many functions options customisation available within packages.","code":""},{"path":"https://hendersontrent.github.io/theftdlc/index.html","id":"whats-in-a-name","dir":"","previous_headings":"General purpose","what":"What’s in a name?","title":"Analyse and Interpret Time Series Features","text":"theftdlc means ‘downloadable content’ (DLC) theft—just like get DLCs expansions video games.","code":""},{"path":"https://hendersontrent.github.io/theftdlc/index.html","id":"quick-tour","dir":"","previous_headings":"","what":"Quick tour","title":"Analyse and Interpret Time Series Features","text":"theft theftdlc combine create intuitive efficient tidy feature-based workflow. example single code chunk calculates features using catch22 custom set mean standard deviation, projects feature space interpretable two-dimensional space using principal components analysis:  example, calculate_features comes theft, project plot generic come theftdlc. Similarly, can perform time-series classification using similar simple workflow compare performance catch22 custom set first two moments distribution: example, classify compare_features come theftdlc. Please see vignette information full functionality packages.","code":"library(dplyr) library(theft) library(theftdlc)  calculate_features(data = theft::simData,                     feature_set = \"catch22\",                    features = list(\"mean\" = mean, \"sd\" = sd)) %>%   project(norm_method = \"RobustSigmoid\",           unit_int = TRUE,           low_dim_method = \"PCA\") %>%   plot() calculate_features(data = theft::simData,                     feature_set = \"catch22\",                    features = list(\"mean\" = mean, \"sd\" = sd)) %>%   classify(by_set = TRUE,            n_resamples = 5,            use_null = TRUE) %>%   compare_features(by_set = TRUE,                    hypothesis = \"null\") %>%   head() hypothesis  feature_set   metric  set_mean null_mean 1 All features != own null All features accuracy 0.8177778 0.1644444 2         User != own null         User accuracy 0.7955556 0.1200000 3      catch22 != own null      catch22 accuracy 0.7511111 0.1377778   t_statistic     p.value 1    4.759301 0.008909773 2    6.159351 0.003526169 3    4.866885 0.008238202"},{"path":"https://hendersontrent.github.io/theftdlc/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Analyse and Interpret Time Series Features","text":"use theft theftdlc work, please cite paper: T. Henderson Ben D. Fulcher. Feature-Based Time-Series Analysis R using theft Package. arXiv, (2022). software:","code":"To cite package 'theft' in publications use:    Henderson T (2025). _theft: Tools for Handling Extraction of Features   from Time Series_. R package version 0.8.1,   <https://hendersontrent.github.io/theft/>.  A BibTeX entry for LaTeX users is    @Manual{,     title = {theft: Tools for Handling Extraction of Features from Time Series},     author = {Trent Henderson},     year = {2025},     note = {R package version 0.8.1},     url = {https://hendersontrent.github.io/theft/},   }  To cite package 'theftdlc' in publications use:    Henderson T (2025). _theftdlc: Analyse and Interpret Time Series   Features_. R package version 0.1.3,   <https://hendersontrent.github.io/theftdlc/>.  A BibTeX entry for LaTeX users is    @Manual{,     title = {theftdlc: Analyse and Interpret Time Series Features},     author = {Trent Henderson},     year = {2025},     note = {R package version 0.1.3},     url = {https://hendersontrent.github.io/theftdlc/},   }"},{"path":"https://hendersontrent.github.io/theftdlc/reference/classify.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit classifiers using time-series features using a resample-based approach and get a fast understanding of performance — classify","title":"Fit classifiers using time-series features using a resample-based approach and get a fast understanding of performance — classify","text":"Fit classifiers using time-series features using resample-based approach get fast understanding performance","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/classify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit classifiers using time-series features using a resample-based approach and get a fast understanding of performance — classify","text":"","code":"classify(   data,   classifier = NULL,   train_size = 0.75,   n_resamples = 30,   by_set = TRUE,   use_null = FALSE,   seed = 123 )  tsfeature_classifier(   data,   classifier = NULL,   train_size = 0.75,   n_resamples = 30,   by_set = TRUE,   use_null = FALSE,   seed = 123 )"},{"path":"https://hendersontrent.github.io/theftdlc/reference/classify.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit classifiers using time-series features using a resample-based approach and get a fast understanding of performance — classify","text":"data feature_calculations object containing raw feature matrix produced theft::calculate_features classifier function specifying classifier fit. function 2 arguments: formula data containing classifier compatible R's predict functionality. Please note classify z-scores data prior modelling using train set's information disabling default scaling function uses recommended. Defaults NULL means following linear SVM fit: classifier = function(formula, data){mod <- e1071::svm(formula, data = data, kernel = \"linear\", scale = FALSE, probability = TRUE)} train_size numeric denoting proportion samples use training set. Defaults 0.75 n_resamples integer denoting number resamples calculate. Defaults 30 by_set Boolean specifying whether compute classifiers feature set. Defaults TRUE. FALSE, function instead find best individually-performing features use_null Boolean whether fit null models class labels shuffled order generate null distribution can compared performance correct class labels. Defaults FALSE seed integer fix R's random number generator ensure reproducibility. Defaults 123","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/classify.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit classifiers using time-series features using a resample-based approach and get a fast understanding of performance — classify","text":"list containing named vector train-test set sizes, data.frame classification performance results","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/classify.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fit classifiers using time-series features using a resample-based approach and get a fast understanding of performance — classify","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/classify.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit classifiers using time-series features using a resample-based approach and get a fast understanding of performance — classify","text":"","code":"library(theft)  features <- theft::calculate_features(theft::simData,   group_var = \"process\",   feature_set = \"catch22\") #> Error in theft::calculate_features(theft::simData, group_var = \"process\",     feature_set = \"catch22\"): unused argument (group_var = \"process\")  classifiers <- classify(features,   by_set = FALSE,   n_resamples = 3) #> Error: object 'features' not found"},{"path":"https://hendersontrent.github.io/theftdlc/reference/cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform cluster analysis of time series using their feature vectors — cluster","title":"Perform cluster analysis of time series using their feature vectors — cluster","text":"Perform cluster analysis time series using feature vectors","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform cluster analysis of time series using their feature vectors — cluster","text":"","code":"cluster(   data,   norm_method = c(\"zScore\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\", \"MaxAbs\"),   unit_int = FALSE,   clust_method = c(\"kmeans\", \"hclust\", \"mclust\"),   k = 2,   features = NULL,   na_removal = c(\"feature\", \"sample\"),   seed = 123,   ... )"},{"path":"https://hendersontrent.github.io/theftdlc/reference/cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform cluster analysis of time series using their feature vectors — cluster","text":"data feature_calculations object containing raw feature matrix produced theft::calculate_features norm_method character denoting rescaling/normalising method apply. Can one \"zScore\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\", \"MaxAbs\". Defaults \"zScore\" unit_int Boolean whether rescale unit interval [0,1] applying normalisation method. Defaults FALSE clust_method character specifying clustering algorithm use. Can one \"kmeans\" k-means clustering, \"hclust\" hierarchical clustering, \"mclust\" Gaussian mixture model clustering. Defaults \"kMeans\" k integer denoting number clusters extract. Defaults 2 features character vector denoting names time-series features use clustering algorithm. Defaults NULL feature filtering usage entire feature matrix na_removal character defining way deal NAs produced feature calculation. Can one \"feature\" \"sample\". \"feature\" removes features produced NAs sample, keeping number samples . \"sample\" omits samples produced least one NA. Defaults \"feature\" seed integer fix R's random number generator ensure reproducibility. Defaults 123 ... arguments passed stats::kmeans stats::hclust, mclust::Mclust depending selection clust_method","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform cluster analysis of time series using their feature vectors — cluster","text":"object class feature_cluster containing clustering algorithm tidy version clusters joined input dataset ready analysis","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/cluster.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Perform cluster analysis of time series using their feature vectors — cluster","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/cluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform cluster analysis of time series using their feature vectors — cluster","text":"","code":"library(theft)  features <- theft::calculate_features(theft::simData,   group_var = \"process\",   feature_set = \"catch22\") #> Error in theft::calculate_features(theft::simData, group_var = \"process\",     feature_set = \"catch22\"): unused argument (group_var = \"process\")  clusts <- cluster(features,   k = 6) #> Error: object 'features' not found"},{"path":"https://hendersontrent.github.io/theftdlc/reference/compare_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Conduct statistical testing on time-series feature classification performance to identify top features or compare entire sets — compare_features","title":"Conduct statistical testing on time-series feature classification performance to identify top features or compare entire sets — compare_features","text":"Conduct statistical testing time-series feature classification performance identify top features compare entire sets","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/compare_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conduct statistical testing on time-series feature classification performance to identify top features or compare entire sets — compare_features","text":"","code":"compare_features(   data,   metric = c(\"accuracy\", \"precision\", \"recall\", \"f1\"),   by_set = TRUE,   hypothesis = c(\"null\", \"pairwise\"),   p_adj = c(\"none\", \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"BY\", \"fdr\") )"},{"path":"https://hendersontrent.github.io/theftdlc/reference/compare_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conduct statistical testing on time-series feature classification performance to identify top features or compare entire sets — compare_features","text":"data list object containing classification outputs produce tsfeature_classifier metric character denoting classification performance metric use statistical testing. Can one \"accuracy\", \"precision\", \"recall\", \"f1\". Defaults \"accuracy\" by_set Boolean specifying whether want compare feature sets (TRUE) individual features (FALSE). Defaults TRUE contingent whether computed set tsfeature_classifier hypothesis character denoting whether p-values calculated feature set feature (depending by_set argument) individually relative null use_null = TRUE tsfeature_classifier \"null\", whether pairwise comparisons set feature conducted main model fits \"pairwise\". Defaults \"null\" p_adj character denoting adjustment made p-values multiple comparisons. valid argument stats::p.adjust. Defaults \"none\" adjustment. \"holm\" recommended starting point adjustments","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/compare_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conduct statistical testing on time-series feature classification performance to identify top features or compare entire sets — compare_features","text":"data.frame containing results","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/compare_features.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Conduct statistical testing on time-series feature classification performance to identify top features or compare entire sets — compare_features","text":"Henderson, T., Bryant, . G., Fulcher, B. D. Never Dull Moment: Distributional Properties Baseline Time-Series Classification. 27th Pacific-Asia Conference Knowledge Discovery Data Mining, (2023).","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/compare_features.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Conduct statistical testing on time-series feature classification performance to identify top features or compare entire sets — compare_features","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/compare_features.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conduct statistical testing on time-series feature classification performance to identify top features or compare entire sets — compare_features","text":"","code":"library(theft)  features <- theft::calculate_features(theft::simData,   group_var = \"process\",   feature_set = NULL,   features = list(\"mean\" = mean, \"sd\" = sd)) #> Error in theft::calculate_features(theft::simData, group_var = \"process\",     feature_set = NULL, features = list(mean = mean, sd = sd)): unused argument (group_var = \"process\")  classifiers <- classify(features,                         by_set = FALSE,                         n_resamples = 3) #> Error: object 'features' not found  compare_features(classifiers,                  by_set = FALSE,                  hypothesis = \"pairwise\") #> Error: object 'classifiers' not found"},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_duplicates.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove duplicate features that exist in multiple feature sets and retain a reproducible random selection of one of them — filter_duplicates","title":"Remove duplicate features that exist in multiple feature sets and retain a reproducible random selection of one of them — filter_duplicates","text":"Remove duplicate features exist multiple feature sets retain reproducible random selection one ","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_duplicates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove duplicate features that exist in multiple feature sets and retain a reproducible random selection of one of them — filter_duplicates","text":"","code":"filter_duplicates(data, preference = NULL, seed = 123)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_duplicates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove duplicate features that exist in multiple feature sets and retain a reproducible random selection of one of them — filter_duplicates","text":"data feature_calculations object containing raw feature matrix produced calculate_features preference deprecated. use seed integer denoting fix R's pseudo-random number generator ensure selections reproducible. Defaults 123","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_duplicates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove duplicate features that exist in multiple feature sets and retain a reproducible random selection of one of them — filter_duplicates","text":"feature_calculations object containing filtered feature data","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_duplicates.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Remove duplicate features that exist in multiple feature sets and retain a reproducible random selection of one of them — filter_duplicates","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_good_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter resample data sets according to good feature list — filter_good_features","title":"Filter resample data sets according to good feature list — filter_good_features","text":"Filter resample data sets according good feature list","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_good_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter resample data sets according to good feature list — filter_good_features","text":"","code":"filter_good_features(data, x, good_features)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_good_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter resample data sets according to good feature list — filter_good_features","text":"data list \"Train\" \"Test\" data x integer denoting resample index operate good_features character vector good features keep","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_good_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter resample data sets according to good feature list — filter_good_features","text":"list filtered train test data","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_good_features.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Filter resample data sets according to good feature list — filter_good_features","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/find_good_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to find features in both train and test set that are ","title":"Helper function to find features in both train and test set that are ","text":"Helper function find features train test set \"good\"","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/find_good_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to find features in both train and test set that are ","text":"","code":"find_good_features(data, x)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/find_good_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to find features in both train and test set that are ","text":"data list \"Train\" \"Test\" data x integer denoting resample index operate ","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/find_good_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to find features in both train and test set that are ","text":"character vector \"good\" feature names","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/find_good_features.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Helper function to find features in both train and test set that are ","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/fit_models.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit classification model and compute key metrics — fit_models","title":"Fit classification model and compute key metrics — fit_models","text":"Fit classification model compute key metrics","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/fit_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit classification model and compute key metrics — fit_models","text":"","code":"fit_models(data, iter_data, row_id, is_null_run = FALSE, classifier)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/fit_models.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit classification model and compute key metrics — fit_models","text":"data list containing train test sets iter_data data.frame containing values iterate seed either feature name set name row_id integer denoting row ID iter_data filter is_null_run Boolean whether calculation null model. Defaults FALSE classifier function specifying classifier fit. function 2 arguments: formula data. Please note tsfeature_classifier z-scores data prior modelling using train set's information disabling default scaling function uses recommended.","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/fit_models.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit classification model and compute key metrics — fit_models","text":"data.frame classification results","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/fit_models.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fit classification model and compute key metrics — fit_models","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/get_rescale_vals.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate central tendency and spread values for all numeric columns in a dataset — get_rescale_vals","title":"Calculate central tendency and spread values for all numeric columns in a dataset — get_rescale_vals","text":"Calculate central tendency spread values numeric columns dataset","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/get_rescale_vals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate central tendency and spread values for all numeric columns in a dataset — get_rescale_vals","text":"","code":"get_rescale_vals(data)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/get_rescale_vals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate central tendency and spread values for all numeric columns in a dataset — get_rescale_vals","text":"data data.frame containing data normalise","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/get_rescale_vals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate central tendency and spread values for all numeric columns in a dataset — get_rescale_vals","text":"list central tendency spread values","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/get_rescale_vals.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate central tendency and spread values for all numeric columns in a dataset — get_rescale_vals","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/interval.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate interval summaries with a measure of central tendency of classification results — interval","title":"Calculate interval summaries with a measure of central tendency of classification results — interval","text":"Calculate interval summaries measure central tendency classification results","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/interval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate interval summaries with a measure of central tendency of classification results — interval","text":"","code":"interval(   data,   metric = c(\"accuracy\", \"precision\", \"recall\", \"f1\"),   by_set = TRUE,   type = c(\"sd\", \"qt\", \"quantile\"),   interval = NULL,   model_type = c(\"main\", \"null\") )  calculate_interval(   data,   metric = c(\"accuracy\", \"precision\", \"recall\", \"f1\"),   by_set = TRUE,   type = c(\"sd\", \"qt\", \"quantile\"),   interval = NULL,   model_type = c(\"main\", \"null\") )"},{"path":"https://hendersontrent.github.io/theftdlc/reference/interval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate interval summaries with a measure of central tendency of classification results — interval","text":"data list object containing classification outputs produce tsfeature_classifier metric character denoting classification performance metric calculate intervals . Can one \"accuracy\", \"precision\", \"recall\", \"f1\". Defaults \"accuracy\" by_set Boolean specifying whether compute intervals feature set. Defaults TRUE. FALSE, function instead calculate intervals feature type character denoting whether calculate +/- SD interval \"sd\", confidence interval based t-distribution \"qt\", based quantile \"quantile\". Defaults \"sd\" interval numeric scalar denoting width interval calculate. Defaults 1 type = \"sd\" produce +/- 1 SD interval. Defaults 0.95 type = \"qt\" type = \"quantile\" 95 per cent interval model_type character denoting whether calculate intervals main models \"main\" null models \"null\" use_null argument using tsfeature_classifier use_null = TRUE. Defaults \"main\"","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/interval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate interval summaries with a measure of central tendency of classification results — interval","text":"interval_calculations object data frame containing results","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/interval.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate interval summaries with a measure of central tendency of classification results — interval","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/interval.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate interval summaries with a measure of central tendency of classification results — interval","text":"","code":"library(theft)  features <- theft::calculate_features(theft::simData,   group_var = \"process\",   feature_set = NULL,   features = list(\"mean\" = mean, \"sd\" = sd)) #> Error in theft::calculate_features(theft::simData, group_var = \"process\",     feature_set = NULL, features = list(mean = mean, sd = sd)): unused argument (group_var = \"process\")  classifiers <- classify(features,   by_set = FALSE,   n_resamples = 3) #> Error: object 'features' not found  interval(classifiers,   by_set = FALSE,   type = \"sd\",   interval = 1) #> Error: object 'classifiers' not found"},{"path":"https://hendersontrent.github.io/theftdlc/reference/make_title.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function for converting to title case — make_title","title":"Helper function for converting to title case — make_title","text":"Helper function converting title case","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/make_title.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function for converting to title case — make_title","text":"","code":"make_title(x)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/make_title.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function for converting to title case — make_title","text":"x character vector","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/make_title.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function for converting to title case — make_title","text":"character vector","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/make_title.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Helper function for converting to title case — make_title","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_calculations.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce a plot for a feature_calculations object — plot.feature_calculations","title":"Produce a plot for a feature_calculations object — plot.feature_calculations","text":"Produce plot feature_calculations object","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_calculations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce a plot for a feature_calculations object — plot.feature_calculations","text":"","code":"# S3 method for class 'feature_calculations' plot(   x,   type = c(\"quality\", \"matrix\", \"cor\", \"violin\"),   norm_method = c(\"zScore\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\", \"MaxAbs\"),   unit_int = FALSE,   clust_method = c(\"average\", \"ward.D\", \"ward.D2\", \"single\", \"complete\", \"mcquitty\",     \"median\", \"centroid\"),   cor_method = c(\"pearson\", \"spearman\"),   feature_names = NULL,   ... )"},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_calculations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce a plot for a feature_calculations object — plot.feature_calculations","text":"x feature_calculations object containing raw feature matrix produced theft::calculate_features type character specifying type plot draw. Defaults \"quality\" norm_method character specifying rescaling/normalising method apply type = \"matrix\" type = \"cor\". Can one \"zScore\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\", \"MaxAbs\". Defaults \"zScore\" unit_int Boolean whether rescale unit interval [0,1] applying normalisation method. Defaults FALSE clust_method character specifying hierarchical clustering method use type = \"matrix\" type = \"cor\". Defaults \"average\" cor_method character specifying correlation method use type = \"cor\". Defaults \"pearson\" feature_names character vector denoting name features plot type = \"violin\". Defaults NULL ... Arguments passed ggplot2::geom_bar type = \"quality\", ggplot2::geom_raster type = \"matrix\", ggplot2::geom_raster type = \"cor\", ggplot2::geom_point type = \"violin\"","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_calculations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produce a plot for a feature_calculations object — plot.feature_calculations","text":"object class ggplot contains graphic","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_calculations.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Produce a plot for a feature_calculations object — plot.feature_calculations","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_projection.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce a plot for a feature_projection object — plot.feature_projection","title":"Produce a plot for a feature_projection object — plot.feature_projection","text":"Produce plot feature_projection object","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_projection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce a plot for a feature_projection object — plot.feature_projection","text":"","code":"# S3 method for class 'feature_projection' plot(x, show_covariance = TRUE, ...)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_projection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce a plot for a feature_projection object — plot.feature_projection","text":"x feature_projection object containing two-dimensional embedding calculated project show_covariance Boolean specifying whether covariance ellipses shown plot. Defaults TRUE ... Arguments passed methods","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_projection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produce a plot for a feature_projection object — plot.feature_projection","text":"object class ggplot contains graphic","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_projection.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Produce a plot for a feature_projection object — plot.feature_projection","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.interval_calculations.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce a plot for a interval_calculations object — plot.interval_calculations","title":"Produce a plot for a interval_calculations object — plot.interval_calculations","text":"Produce plot interval_calculations object","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.interval_calculations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce a plot for a interval_calculations object — plot.interval_calculations","text":"","code":"# S3 method for class 'interval_calculations' plot(x, ...)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.interval_calculations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce a plot for a interval_calculations object — plot.interval_calculations","text":"x interval_calculations object containing summary calculated interval ... Arguments passed methods show_covariance Boolean specifying whether covariance ellipses shown plot. Defaults TRUE","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.interval_calculations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produce a plot for a interval_calculations object — plot.interval_calculations","text":"object class ggplot contains graphic","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.interval_calculations.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Produce a plot for a interval_calculations object — plot.interval_calculations","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/project.html","id":null,"dir":"Reference","previous_headings":"","what":"Project a feature matrix into a two-dimensional representation using PCA, MDS, t-SNE, or UMAP ready for plotting — project","title":"Project a feature matrix into a two-dimensional representation using PCA, MDS, t-SNE, or UMAP ready for plotting — project","text":"Project feature matrix two-dimensional representation using PCA, MDS, t-SNE, UMAP ready plotting","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/project.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project a feature matrix into a two-dimensional representation using PCA, MDS, t-SNE, or UMAP ready for plotting — project","text":"","code":"project(   data,   norm_method = c(\"zScore\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\", \"MaxAbs\"),   unit_int = FALSE,   low_dim_method = c(\"PCA\", \"tSNE\", \"ClassicalMDS\", \"KruskalMDS\", \"SammonMDS\", \"UMAP\"),   na_removal = c(\"feature\", \"sample\"),   seed = 123,   ... )  reduce_dims(   data,   norm_method = c(\"zScore\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\", \"MaxAbs\"),   unit_int = FALSE,   low_dim_method = c(\"PCA\", \"tSNE\", \"ClassicalMDS\", \"KruskalMDS\", \"SammonMDS\", \"UMAP\"),   na_removal = c(\"feature\", \"sample\"),   seed = 123,   ... )"},{"path":"https://hendersontrent.github.io/theftdlc/reference/project.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project a feature matrix into a two-dimensional representation using PCA, MDS, t-SNE, or UMAP ready for plotting — project","text":"data feature_calculations object containing raw feature matrix produced theft::calculate_features norm_method character denoting rescaling/normalising method apply. Can one \"zScore\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\", \"MaxAbs\". Defaults \"zScore\" unit_int Boolean whether rescale unit interval [0,1] applying normalisation method. Defaults FALSE low_dim_method character specifying low dimensional embedding method use. Can one \"PCA\", \"tSNE\", \"ClassicalMDS\", \"KruskalMDS\", \"SammonMDS\", \"UMAP\". Defaults \"PCA\" na_removal character defining way deal NAs produced feature calculation. Can one \"feature\" \"sample\". \"feature\" removes features produced NAs sample, keeping number samples . \"sample\" omits samples produced least one NA. Defaults \"feature\" seed integer fix R's random number generator ensure reproducibility. Defaults 123 ... arguments passed stats::prcomp Rtsne::Rtsne, stats::cmdscale, MASS::isoMDS, MASS::sammon, umap::umap depending selection low_dim_method","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/project.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Project a feature matrix into a two-dimensional representation using PCA, MDS, t-SNE, or UMAP ready for plotting — project","text":"object class feature_projection named list containing feature_calculations data supplied function, wide matrix filtered data, tidy data.frame projected 2-D data, model fit object","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/project.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Project a feature matrix into a two-dimensional representation using PCA, MDS, t-SNE, or UMAP ready for plotting — project","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/project.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Project a feature matrix into a two-dimensional representation using PCA, MDS, t-SNE, or UMAP ready for plotting — project","text":"","code":"# \\donttest{  library(theft)  features <- theft::calculate_features(theft::simData,   group_var = \"process\",   feature_set = \"catch22\") #> Error in theft::calculate_features(theft::simData, group_var = \"process\",     feature_set = \"catch22\"): unused argument (group_var = \"process\")  pca <- project(features,   norm_method = \"zScore\",   low_dim_method = \"PCA\") #> Error: object 'features' not found # }"},{"path":"https://hendersontrent.github.io/theftdlc/reference/resample_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to create a resampled dataset — resample_data","title":"Helper function to create a resampled dataset — resample_data","text":"Helper function create resampled dataset","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/resample_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to create a resampled dataset — resample_data","text":"","code":"resample_data(data, train_rows, test_rows, train_groups, test_groups, seed)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/resample_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to create a resampled dataset — resample_data","text":"data data.frame containing time-series features train_rows integer denoting number cases train set test_rows integer denoting number cases test set train_groups data.frame containing proportions class original train split test_groups data.frame containing proportions class original test split seed integer denoting fixed value R's pseudorandom number generator","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/resample_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to create a resampled dataset — resample_data","text":"list containing new train test data","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/resample_data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Helper function to create a resampled dataset — resample_data","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/rescale_zscore.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate z-score for all columns in a dataset using train set central tendency and spread — rescale_zscore","title":"Calculate z-score for all columns in a dataset using train set central tendency and spread — rescale_zscore","text":"Calculate z-score columns dataset using train set central tendency spread","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/rescale_zscore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate z-score for all columns in a dataset using train set central tendency and spread — rescale_zscore","text":"","code":"rescale_zscore(data, rescalers)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/rescale_zscore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate z-score for all columns in a dataset using train set central tendency and spread — rescale_zscore","text":"data data.frame containing data normalise rescalers list containing central tendency spread values train set","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/rescale_zscore.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate z-score for all columns in a dataset using train set central tendency and spread — rescale_zscore","text":"data.frame rescaled data","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/rescale_zscore.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate z-score for all columns in a dataset using train set central tendency and spread — rescale_zscore","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/select_stat_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to select only the relevant columns for statistical testing — select_stat_cols","title":"Helper function to select only the relevant columns for statistical testing — select_stat_cols","text":"Helper function select relevant columns statistical testing","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/select_stat_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to select only the relevant columns for statistical testing — select_stat_cols","text":"","code":"select_stat_cols(data, by_set, metric, hypothesis)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/select_stat_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to select only the relevant columns for statistical testing — select_stat_cols","text":"data data.frame classification accuracy results by_set Boolean specifying whether want compare feature sets (TRUE) individual features (FALSE). metric character denoting classification performance metric use statistical testing. Can one \"accuracy\", \"precision\", \"recall\", \"f1\". Defaults \"accuracy\" hypothesis character denoting whether p-values calculated feature set feature (depending by_set argument) individually relative null use_null = TRUE tsfeature_classifier \"null\", whether pairwise comparisons set feature conducted main model fits \"pairwise\".","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/select_stat_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to select only the relevant columns for statistical testing — select_stat_cols","text":"object class data.frame","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/select_stat_cols.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Helper function to select only the relevant columns for statistical testing — select_stat_cols","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/shrink.html","id":null,"dir":"Reference","previous_headings":"","what":"Use a cross validated penalized maximum likelihood generalized linear model to perform feature selection — shrink","title":"Use a cross validated penalized maximum likelihood generalized linear model to perform feature selection — shrink","text":"Use cross validated penalized maximum likelihood generalized linear model perform feature selection","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/shrink.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use a cross validated penalized maximum likelihood generalized linear model to perform feature selection — shrink","text":"","code":"shrink(data, threshold = c(\"one\", \"all\"), plot = FALSE, ...)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/shrink.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use a cross validated penalized maximum likelihood generalized linear model to perform feature selection — shrink","text":"data feature_calculations object containing raw feature matrix produced theft::calculate_features threshold character denoting whether retain features least one non-zero coefficient \"one\" across group levels features non-zero coefficients across group levels \"\". Applicable multinomial case . Defaults \"one\" less aggressive filtering plot Boolean whether draw misclassification error lambda plot cv.glmnet object. Defaults FALSE ... arguments passed glmnet::cv.glmnet","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/shrink.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use a cross validated penalized maximum likelihood generalized linear model to perform feature selection — shrink","text":"feature_calculations object containing data frame reduced feature set","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/shrink.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Use a cross validated penalized maximum likelihood generalized linear model to perform feature selection — shrink","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/shrink.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use a cross validated penalized maximum likelihood generalized linear model to perform feature selection — shrink","text":"","code":"library(theft)  features <- theft::calculate_features(theft::simData,   group_var = \"process\",   feature_set = \"catch22\") #> Error in theft::calculate_features(theft::simData, group_var = \"process\",     feature_set = \"catch22\"): unused argument (group_var = \"process\")  best_features <- shrink(features) #> Error: object 'features' not found"},{"path":"https://hendersontrent.github.io/theftdlc/reference/stat_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate p-values for feature sets or features relative to an empirical null or each other using resampled t-tests — stat_test","title":"Calculate p-values for feature sets or features relative to an empirical null or each other using resampled t-tests — stat_test","text":"Calculate p-values feature sets features relative empirical null using resampled t-tests","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/stat_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate p-values for feature sets or features relative to an empirical null or each other using resampled t-tests — stat_test","text":"","code":"stat_test(   data,   iter_data,   row_id,   by_set = FALSE,   hypothesis,   metric,   train_test_sizes,   n_resamples )"},{"path":"https://hendersontrent.github.io/theftdlc/reference/stat_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate p-values for feature sets or features relative to an empirical null or each other using resampled t-tests — stat_test","text":"data data.frame raw classification accuracy results iter_data data.frame containing values iterate seed either feature name set name row_id integer denoting row ID iter_data filter by_set Boolean specifying whether want compare feature sets (TRUE) individual features (FALSE). hypothesis character denoting whether p-values calculated feature set feature (depending by_set argument) individually relative null use_null = TRUE tsfeature_classifier \"null\", whether pairwise comparisons set feature conducted main model fits \"pairwise\". metric character denoting classification performance metric use statistical testing. Can one \"accuracy\", \"precision\", \"recall\", \"f1\". Defaults \"accuracy\" train_test_sizes integer vector containing train test set sample sizes n_resamples integer denoting number resamples calculated","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/stat_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate p-values for feature sets or features relative to an empirical null or each other using resampled t-tests — stat_test","text":"object class data.frame","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/stat_test.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate p-values for feature sets or features relative to an empirical null or each other using resampled t-tests — stat_test","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/theftdlc.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyse and Interpret Time Series Features — theftdlc","title":"Analyse and Interpret Time Series Features — theftdlc","text":"Analyse Interpret Time Series Features","code":""}]
