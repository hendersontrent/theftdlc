[{"path":"https://hendersontrent.github.io/theftdlc/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 Trent Henderson Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"purpose","dir":"Articles","previous_headings":"","what":"Purpose","title":"Introduction to theftdlc","text":"theft package R facilitates user-friendly access structured analytical workflow extraction time-series features six different feature sets (set user-supplied features): \"catch22\", \"feasts\", \"Kats\", \"tsfeatures\", \"tsfresh\", \"TSFEL\" theftdlc extends feature-based ecosystem providing suite functions analysing, interpreting, visualising time-series features calculated using theft.","code":""},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"core-calculation-functions","dir":"Articles","previous_headings":"","what":"Core calculation functions","title":"Introduction to theftdlc","text":"explore package functionality, going use dataset comes standard theft called simData. dataset contains collection randomly generated time series six different types processes. dataset can accessed via: data follows following structure: use theft quickly calculate features using catch22 set:","code":"theft::simData head(simData) #>                      values timepoint               id        process #> Gaussian Noise.1 -0.6264538         1 Gaussian Noise_1 Gaussian Noise #> Gaussian Noise.2  0.1836433         2 Gaussian Noise_1 Gaussian Noise #> Gaussian Noise.3 -0.8356286         3 Gaussian Noise_1 Gaussian Noise #> Gaussian Noise.4  1.5952808         4 Gaussian Noise_1 Gaussian Noise #> Gaussian Noise.5  0.3295078         5 Gaussian Noise_1 Gaussian Noise #> Gaussian Noise.6 -0.8204684         6 Gaussian Noise_1 Gaussian Noise feature_matrix <- calculate_features(data = simData,                                       id_var = \"id\",                                       time_var = \"timepoint\",                                       values_var = \"values\",                                       group_var = \"process\",                                       feature_set = \"catch22\",                                      seed = 123)"},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"data-quality-checks","dir":"Articles","previous_headings":"","what":"Data quality checks","title":"Introduction to theftdlc","text":"core calculate_features function theft returns object class feature_calculations. Objects type purposefully looked-functions theftdlc. class, simple methods plot() can called object produce range statistical graphics. first visualisation data types calculated feature vectors. useful inspecting features might need dropped due large proportions undesirable (e.g., NA, NaN etc.) values. can specify plot type = \"quality make graphic:","code":"plot(feature_matrix, type = \"quality\")"},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"data-visualisation-and-low-dimensional-projections","dir":"Articles","previous_headings":"","what":"Data visualisation and low-dimensional projections","title":"Introduction to theftdlc","text":"package also comes additional statistical graphical functionality: Feature time-series matrix heatmap Low dimensional projections feature space plotting scatterplot Pairwise feature correlation matrix heatmap","code":""},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"feature-matrices","dir":"Articles","previous_headings":"Data visualisation and low-dimensional projections","what":"Feature matrices","title":"Introduction to theftdlc","text":"function calling type = \"matrix\" plot() feature_calculations object takes produces ggplot object heatmap showing feature vectors across x axis time series y axis. Prior plotting, function hierarchically clusters data across rows columns visually highlight empirical structure. Note several options hierarchical clustering linkage algorithm use: \"average\" (default) \"ward.D\" \"ward.D2\" \"single\" \"complete\" \"mcquitty\" \"median\" \"centroid\" See hclust documentation information. Note legend plot (matrix visualisations theftdlc) discretised visual clarity continuous legends can difficult interpret meaningful value differences easily.  can control normalisation type norm_method argument, whether rescale unit interval normalisation unit_int argument. norm_method normalisation feature vectors theftdlc handled normaliseR package. can also control hierarchical clustering method clust_method argument (example used defaults manual specification needed).","code":"plot(feature_matrix, type = \"matrix\", norm_method = \"RobustSigmoid\")"},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"individual-feature-distributions","dir":"Articles","previous_headings":"Data visualisation and low-dimensional projections","what":"Individual feature distributions","title":"Introduction to theftdlc","text":"Plotting entire feature matrix useful, sometimes wish understand distributions individual features. particularly useful different groups data (time-series classification context). can use plot() generic draw violin plots setting type = \"violin\". Note violin plots, also need tell function features wish plot (.e., vector characters specifying feature names names column feature_calculations object). simplicity, just plot two random features catch22 :  Note using defined plot() generics, can pass additional arguments certain geoms control plot look ... argument plot() function. guide arguments go depending plot type: type = \"quality\"—... goes ggplot2::geom_bar type = \"matrix\"—... goes ggplot2::geom_raster type = \"cor\"—... goes ggplot2::geom_raster type = \"violin\"—... goes ggplot2::geom_point example, may wish control point size transparency plot (rendered space):","code":"plot(feature_matrix, type = \"violin\",      feature_names = c(\"CO_f1ecac\", \"PD_PeriodicityWang_th0_01\")) plot(feature_matrix, type = \"violin\",      feature_names = c(\"CO_f1ecac\", \"PD_PeriodicityWang_th0_01\"),      size = 0.7, alpha = 0.9)"},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"low-dimensional-projections","dir":"Articles","previous_headings":"Data visualisation and low-dimensional projections","what":"Low dimensional projections","title":"Introduction to theftdlc","text":"Low-dimensional projections useful tool visualising structure high-dimensional datasets low-dimensional spaces. machine learning time-series data, often interested representing time-series dataset two-dimensional projection high-dimensional feature space. projection can reveal structure dataset, including different labeled classes organized. theftdlc function project takes feature_calculations object performs one following dimension reduction techniques reduce dimensionality bivariate state can easily plotted: Principal components analysis (PCA)—\"PCA\" \\(t\\)-Stochastic Neighbor Embedding (\\(t\\)-SNE)—\"tSNE\" Classical multidimensional scaling (MDS)—\"ClassicalMDS\" Kruskal’s non-metric multidimensional scaling—\"KruskalMDS\" Sammon’s non-linear mapping non-metric multidimensional scaling—\"SammonMDS\" Uniform Manifold Approximation Projection Dimension Reduction (UMAP)—\"UMAP\" result stored custom object class called feature_projection. project takes following arguments: data—feature_calculations object containing raw feature matrix produced theft::calculate_features norm_method—character denoting rescaling/normalising method apply. Can one \"zScore\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\", \"MaxAbs\". Defaults \"zScore\" unit_int—Boolean whether rescale unit interval \\([0,1]\\) applying normalisation method. Defaults FALSE low_dim_method—character specifying low dimensional embedding method use. Can one \"PCA\" \"tSNE\", \"ClassicalMDS\", \"KruskalMDS\", \"SammonMDS\", \"UMAP\". Defaults \"PCA\" na_removal—character defining way deal NAs produced feature calculation. Can one \"feature\" \"sample\". \"feature\" removes features produced NAs sample, keeping number samples . \"sample\" omits samples produced least one NA. Defaults \"feature\" seed—integer fix R’s random number generator ensure reproducibility. Defaults 123 ... arguments passed respective function specified low_dim_method project returns object class feature_projection essentially named list comprised four elements: \"Data\"—feature_calculations object supplied project \"ModelData\"—wide matrix filtered data supplied model fit \"ProjectedData\"—tidy data.frame two-dimensional embedding \"ModelFit\"—raw model object dimensionality reduction algorithm can similarly call plot() object produce two-dimensional scatterplot results:  another example, t-SNE version can specified similar fashion, function parameters method supplied ... argument project. Shaded covariance ellipses can also disabled plotting feature_projection objects setting show_covariance = FALSE. example modify perplexity t-SNE algorithm:","code":"low_dim <- project(feature_matrix,                    norm_method = \"RobustSigmoid\",                    unit_int = TRUE,                    low_dim_method = \"PCA\",                    seed = 123) plot(low_dim) low_dim2 <- project(feature_matrix,                     norm_method = \"RobustSigmoid\",                     unit_int = TRUE,                     low_dim_method = \"tSNE\",                     perplexity = 10,                     seed = 123)  plot(low_dim2, show_covariance = FALSE)"},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"pairwise-correlations","dir":"Articles","previous_headings":"Data visualisation and low-dimensional projections","what":"Pairwise correlations","title":"Introduction to theftdlc","text":"can plot correlations feature vectors using plot(type = \"cor\") feature_calculations object:  Similarly, can control normalisation type norm_method argument hierarchical clustering method clust_method argument (example used defaults manual specification needed).","code":"plot(feature_matrix, type = \"cor\")"},{"path":[]},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"feature-by-feature","dir":"Articles","previous_headings":"Time-series classification","what":"Feature-by-feature","title":"Introduction to theftdlc","text":"Since feature-based time-series analysis shown particular promise classification problems, theftdlc includes functionality exploring group separation. function classify enables fit range classification models enable statistical comparisons using resampling methodology presented paper detailed review1. function meant serve fast answer can used guide analysis replacement development careful statistical pipeline. classify following arguments: data—feature_calculations object containing raw feature matrix produced theft::calculate_features included group column per theft::calculate_features classifier—function specifying classifier fit. function 2 arguments: formula data. Please note classify z-scores data prior modelling using train set’s information disabling default scaling function uses recommended. Defaults NULL means following linear SVM fit: classifier = function(formula, data){mod <- e1071::svm(formula, data = data, kernel = \"linear\", scale = FALSE, probability = TRUE)} train_size—Numeric value denoting proportion samples use training set. Defaults 0.75 n_resamples—Integer denoting number resamples calculate. Defaults 30 by_set—Boolean specifying whether compute classifiers feature set. Defaults TRUE (see section “Multi-feature” ). FALSE, function instead find best individually-performing features use_null—Boolean whether fit null models class labels shuffled order generate null distribution can compared performance correct class labels. Defaults FALSE. known permutation testing seed—Integer fix R’s random number generator ensure reproducibility. Defaults 123 Since interested individual features section, calculate main null results feature using just 5 resamples efficiency (practice, use !) default linear SVM: show simple specify different classifier, can instead maybe use radial basis function SVM (though absolutely limited just e1071 models! can use anything can used R’s predict generic classify internally constructs confusion matrices model predictions): raw classification results useful, often also like statistical evaluate facet . theftdlc includes function compare_features . compare_features contains following arguments: data—List object containing classification outputs produce classify metric—Character denoting classification performance metric use statistical testing. Can one \"accuracy\", \"precision\", \"recall\", \"f1\". Defaults \"accuracy\" by_set—Boolean specifying whether want compare feature sets (TRUE) individual features (FALSE). Defaults TRUE contingent whether computed set classify hypothesis—Character denoting whether p-values calculated feature set feature (depending by_set argument) individually relative null use_null = TRUE classify \"null\", whether pairwise comparisons set feature conducted main model fits \"pairwise\". Defaults \"null\" p_adj—Character denoting adjustment made p-values multiple comparisons. valid argument stats::p.adjust. Defaults \"none\" adjustment. \"holm\" recommended starting point adjustments sought can use compare_features evaluate well individual feature performs relative empirical null distribution (noting using defaults arguments code cleanliness): conduct pairwise comparisons individual features: can use ggplot2 summarise visualise results. pairwise correlation plot top 10 features catch22 toy problem. just simply filtering original full feature data making use plot generic defined objects class feature_calculations:  can also easily draw violin plot top 10 features visualise distributions group:  Finally, theftdlc also contains function interval summarising results classify. interval takes following arguments: data—list object containing classification outputs produce classify metric—character denoting classification performance metric calculate intervals . Can one \"accuracy\", \"precision\", \"recall\", \"f1\". Defaults \"accuracy\" by_set—Boolean specifying whether compute intervals feature set. Defaults TRUE. FALSE, function instead calculate intervals feature type—character denoting whether calculate \\(\\pm\\) SD interval \"sd\", confidence interval based \\(t\\)-distribution \"qt\", based quantile \"quantile\". Defaults \"sd\" interval—numeric scalar denoting width interval calculate. Defaults 1 type = \"sd\" produce \\(\\pm 1\\) SD interval. Defaults 0.95 type = \"qt\" type = \"quantile\" \\(95\\%\\) interval model_type—character denoting whether calculate intervals main models \"main\" null models \"null\" use_null argument using classify use_null = TRUE. Defaults \"main\" can evidently use interval produce variety different summaries us. example, might wish compute \\(\\pm1\\) SD interval feature’s main model classification accuracy values (note defaults function us, need set by_set = FALSE manually):","code":"feature_classifiers <- classify(feature_matrix,                                 by_set = FALSE,                                 n_resamples = 5,                                 use_null = TRUE) myclassifier <- function(formula, data){   mod <- e1071::svm(formula, data = data, kernel = \"radial\", scale = FALSE,                     probability = TRUE) }  feature_classifiers_radial <- classify(feature_matrix,                                        classifier = myclassifier,                                        by_set = FALSE,                                        n_resamples = 5,                                        use_null = TRUE) feature_vs_null <- compare_features(feature_classifiers,                                     by_set = FALSE,                                     hypothesis = \"null\")  head(feature_vs_null) #>                                                 hypothesis #> 1 catch22_CO_Embed2_Dist_tau_d_expfit_meandiff != own null #> 2                            catch22_CO_f1ecac != own null #> 3                       catch22_CO_FirstMin_ac != own null #> 4             catch22_CO_HistogramAMI_even_2_5 != own null #> 5                        catch22_CO_trev_1_num != own null #> 6                  catch22_DN_HistogramMode_10 != own null #>                                          names #> 1 catch22_CO_Embed2_Dist_tau_d_expfit_meandiff #> 2                            catch22_CO_f1ecac #> 3                       catch22_CO_FirstMin_ac #> 4             catch22_CO_HistogramAMI_even_2_5 #> 5                        catch22_CO_trev_1_num #> 6                  catch22_DN_HistogramMode_10 #>                         original_names feature_set   metric feature_mean #> 1 CO_Embed2_Dist_tau_d_expfit_meandiff     catch22 accuracy   0.40444444 #> 2                            CO_f1ecac     catch22 accuracy   0.29777778 #> 3                       CO_FirstMin_ac     catch22 accuracy   0.31111111 #> 4             CO_HistogramAMI_even_2_5     catch22 accuracy   0.29777778 #> 5                        CO_trev_1_num     catch22 accuracy   0.11111111 #> 6                  DN_HistogramMode_10     catch22 accuracy   0.08444444 #>    null_mean t_statistic     p.value #> 1 0.12000000    4.894202 0.008077588 #> 2 0.09777778    2.371708 0.076678140 #> 3 0.09777778    2.317462 0.081362957 #> 4 0.10666667    2.007068 0.115183542 #> 5 0.07111111    3.674235 0.021311641 #> 6 0.06666667    0.560112 0.605286626 pairwise_features <- compare_features(feature_classifiers,                                       by_set = FALSE,                                       hypothesis = \"pairwise\",                                       p_adj = \"holm\")  head(pairwise_features) #>                                                                         hypothesis #> 1                catch22_CO_Embed2_Dist_tau_d_expfit_meandiff != catch22_CO_f1ecac #> 2           catch22_CO_Embed2_Dist_tau_d_expfit_meandiff != catch22_CO_FirstMin_ac #> 3 catch22_CO_Embed2_Dist_tau_d_expfit_meandiff != catch22_CO_HistogramAMI_even_2_5 #> 4            catch22_CO_Embed2_Dist_tau_d_expfit_meandiff != catch22_CO_trev_1_num #> 5      catch22_CO_Embed2_Dist_tau_d_expfit_meandiff != catch22_DN_HistogramMode_10 #> 6       catch22_CO_Embed2_Dist_tau_d_expfit_meandiff != catch22_DN_HistogramMode_5 #>                                        names_a                          names_b #> 1 catch22_CO_Embed2_Dist_tau_d_expfit_meandiff                catch22_CO_f1ecac #> 2 catch22_CO_Embed2_Dist_tau_d_expfit_meandiff           catch22_CO_FirstMin_ac #> 3 catch22_CO_Embed2_Dist_tau_d_expfit_meandiff catch22_CO_HistogramAMI_even_2_5 #> 4 catch22_CO_Embed2_Dist_tau_d_expfit_meandiff            catch22_CO_trev_1_num #> 5 catch22_CO_Embed2_Dist_tau_d_expfit_meandiff      catch22_DN_HistogramMode_10 #> 6 catch22_CO_Embed2_Dist_tau_d_expfit_meandiff       catch22_DN_HistogramMode_5 #>     metric names_a_mean names_b_mean t_statistic      p.value p_value_adj #> 1 accuracy    0.4044444   0.29777778    5.237229 6.352257e-03   1.0000000 #> 2 accuracy    0.4044444   0.31111111    3.500000 2.489616e-02   1.0000000 #> 3 accuracy    0.4044444   0.29777778    2.449490 7.048400e-02   1.0000000 #> 4 accuracy    0.4044444   0.11111111    9.241849 7.620017e-04   0.1699264 #> 5 accuracy    0.4044444   0.08444444    6.743418 2.520576e-03   0.5368828 #> 6 accuracy    0.4044444   0.06222222   15.717559 9.571521e-05   0.0220145 top_10 <- feature_vs_null %>%   dplyr::slice_min(p.value, n = 10) %>%   dplyr::select(c(feature_set, original_names, p.value))  feature_matrix_filt <- feature_matrix %>%   dplyr::filter(feature_set %in% top_10$feature_set & names %in% top_10$original_names)  feature_matrix_filt <- structure(feature_matrix_filt, class = c(\"feature_calculations\", \"data.frame\")) plot(feature_matrix_filt, type = \"cor\") plot(feature_matrix_filt,      type = \"violin\",      feature_names = top_10$original_names) interval(feature_classifiers, by_set = FALSE) #>                                                  names      .mean     .lower #> 1         catch22_CO_Embed2_Dist_tau_d_expfit_meandiff 0.40444444 0.38585200 #> 2                                    catch22_CO_f1ecac 0.29777778 0.27790162 #> 3                               catch22_CO_FirstMin_ac 0.31111111 0.28888889 #> 4                     catch22_CO_HistogramAMI_even_2_5 0.29777778 0.26407611 #> 5                                catch22_CO_trev_1_num 0.11111111 0.09539763 #> 6                          catch22_DN_HistogramMode_10 0.08444444 0.05547021 #> 7                           catch22_DN_HistogramMode_5 0.06222222 0.05228414 #> 8                catch22_DN_OutlierInclude_n_001_mdrmd 0.05777778 0.04560617 #> 9                catch22_DN_OutlierInclude_p_001_mdrmd 0.06222222 0.02246990 #> 10              catch22_FC_LocalSimple_mean1_tauresrat 0.28888889 0.25746192 #> 11                 catch22_FC_LocalSimple_mean3_stderr 0.50222222 0.47688499 #> 12     catch22_IN_AutoMutualInfoStats_40_gaussian_fmmi 0.29333333 0.27474089 #> 13                        catch22_MD_hrv_classic_pnn40 0.25333333 0.18931173 #> 14                   catch22_PD_PeriodicityWang_th0_01 0.15111111 0.13251867 #> 15            catch22_SB_BinaryStats_diff_longstretch0 0.33333333 0.28121760 #> 16            catch22_SB_BinaryStats_mean_longstretch1 0.35111111 0.30836581 #> 17                   catch22_SB_MotifThree_quantile_hh 0.46222222 0.43324799 #> 18          catch22_SB_TransitionMatrix_3ac_sumdiagcov 0.32000000 0.27391902 #> 19      catch22_SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1 0.08444444 0.06010122 #> 20 catch22_SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1 0.25333333 0.22799610 #> 21            catch22_SP_Summaries_welch_rect_area_5_1 0.60000000 0.56486358 #> 22            catch22_SP_Summaries_welch_rect_centroid 0.53333333 0.50611678 #>        .upper #> 1  0.42303689 #> 2  0.31765394 #> 3  0.33333333 #> 4  0.33147945 #> 5  0.12682460 #> 6  0.11341868 #> 7  0.07216030 #> 8  0.06994939 #> 9  0.10197454 #> 10 0.32031586 #> 11 0.52755945 #> 12 0.31192578 #> 13 0.31735493 #> 14 0.16970356 #> 15 0.38544906 #> 16 0.39385641 #> 17 0.49119646 #> 18 0.36608098 #> 19 0.10878767 #> 20 0.27867057 #> 21 0.63513642 #> 22 0.56054989"},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"multi-feature","dir":"Articles","previous_headings":"Time-series classification","what":"Multi-feature","title":"Introduction to theftdlc","text":"Since theft contains entire sets features, can also use classify compare set level by_set argument. Let’s try catch22 custom set just mean standard deviation: Note classify constructs set \"features\" (.e., features across computed sets) automatically \\(>2\\) unique feature sets detected feature data. Similar individual feature case, can also use interval combined ggplot2 summarise findings. comparison mean accuracy \\(\\pm 1SD\\) feature sets:","code":"feature_matrix2 <- calculate_features(data = simData,                                        group_var = \"process\",                                        feature_set = \"catch22\",                                       features = list(\"mean\" = mean, \"sd\" = sd),                                       seed = 123)  set_classifiers <- classify(feature_matrix2,                                         by_set = TRUE,                                         n_resamples = 5,                                         use_null = TRUE)  head(set_classifiers) #> $TrainTestSizes #> train_size  test_size  #>        135         45  #>  #> $ClassificationResults #>    model_type resample   accuracy mean_precision mean_recall mean_f1_score #> 1        Main        1 0.86666667     0.90235690  0.90235690     0.9000000 #> 2        Main        2 0.84444444     0.88047138  0.88194444     0.8806479 #> 3        Main        3 0.80000000     0.84785354  0.82702020     0.8317460 #> 4        Main        4 0.82222222     0.86195286  0.86446886     0.8611111 #> 5        Main        5 0.86666667     0.89562290  0.90109890     0.8958333 #> 6        Null        1 0.15555556     0.16734007  0.15575397     0.2266282 #> 7        Null        2 0.13333333     0.18518519  0.10370370     0.3771930 #> 8        Null        3 0.06666667     0.10404040  0.07936508     0.1444444 #> 9        Null        4 0.24444444     0.26153199  0.27103175     0.2406925 #> 10       Null        5 0.24444444     0.22853535  0.23164683     0.2714130 #> 11       Main        1 0.71111111     0.79629630  0.83285714     0.8658046 #> 12       Main        2 0.73333333     0.81481481  0.85666667     0.8941914 #> 13       Main        3 0.68888889     0.77546296  0.78285714     0.8238998 #> 14       Main        4 0.71111111     0.79629630  0.83285714     0.8658046 #> 15       Main        5 0.68888889     0.77777778  0.81500000     0.8379841 #> 16       Null        1 0.00000000     0.00000000  0.00000000           NaN #> 17       Null        2 0.28888889     0.35416667  0.35294118     0.4358312 #> 18       Null        3 0.04444444     0.04166667  0.20000000     0.4000000 #> 19       Null        4 0.11111111     0.20833333  0.26923077     0.2714286 #> 20       Null        5 0.11111111     0.16666667  0.06410256     0.2272727 #> 21       Main        1 0.68888889     0.72727273  0.68398268     0.6865741 #> 22       Main        2 0.62222222     0.59764310  0.60178710     0.7068449 #> 23       Main        3 0.75555556     0.80744949  0.75476190     0.7578947 #> 24       Main        4 0.77777778     0.79124579  0.77167508     0.7766106 #> 25       Main        5 0.68888889     0.76430976  0.70138889     0.7086835 #> 26       Null        1 0.17777778     0.19730640  0.19444444     0.3869031 #> 27       Null        2 0.08888889     0.10774411  0.08215488     0.1638889 #> 28       Null        3 0.08888889     0.08552189  0.12500000     0.1939394 #> 29       Null        4 0.26666667     0.24532828  0.27420635     0.3099160 #> 30       Null        5 0.17777778     0.15172559  0.14587496     0.2203209 #>      feature_set #> 1   All features #> 2   All features #> 3   All features #> 4   All features #> 5   All features #> 6   All features #> 7   All features #> 8   All features #> 9   All features #> 10  All features #> 11 User-supplied #> 12 User-supplied #> 13 User-supplied #> 14 User-supplied #> 15 User-supplied #> 16 User-supplied #> 17 User-supplied #> 18 User-supplied #> 19 User-supplied #> 20 User-supplied #> 21       catch22 #> 22       catch22 #> 23       catch22 #> 24       catch22 #> 25       catch22 #> 26       catch22 #> 27       catch22 #> 28       catch22 #> 29       catch22 #> 30       catch22 interval_calcs <- interval(set_classifiers)  interval_calcs %>%   ggplot2::ggplot(ggplot2::aes(x = reorder(feature_set, -.mean), y = .mean,                                colour = feature_set)) +   ggplot2::geom_errorbar(ggplot2::aes(ymin = .lower, ymax = .upper)) +   ggplot2::geom_point(size = 5) +   ggplot2::labs(x = \"Feature set\",                 y = \"Classification accuracy\") +   ggplot2::scale_colour_brewer(palette = \"Dark2\") +   ggplot2::theme_bw() +   ggplot2::theme(legend.position = \"none\",                  panel.grid.minor = ggplot2::element_blank())"},{"path":"https://hendersontrent.github.io/theftdlc/articles/theftdlc.html","id":"cluster-analysis","dir":"Articles","previous_headings":"","what":"Cluster analysis","title":"Introduction to theftdlc","text":"theftdlc also supports quick simple cluster analysis using either \\(k\\)-means, hierarchical clustering, Gaussian mixture models cluster function. cluster takes similar key arguments theftdlc functions (though defaults set , data required cluster work): data—feature_calculations object containing raw feature matrix produced theft::calculate_features norm_method—character denoting rescaling/normalising method apply. Can one \"zScore\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\", \"MaxAbs\". Defaults \"zScore\" unit_int—Boolean whether rescale unit interval \\([0,1]\\) applying normalisation method. Defaults FALSE clust_method—character specifying clustering algorithm use. Can one \"kmeans\", \"hclust\", \"mclust\". Defaults \"kmeans\" k—integer denoting number clusters extract. Defaults 2 features—character vector denoting names time-series features use clustering algorithm. Defaults NULL feature filtering usage entire feature matrix na_removal—character defining way deal NAs produced feature calculation. Can one \"feature\" \"sample\". \"feature\" removes features produced NAs sample, keeping number samples . \"sample\" omits samples produced least one NA. Defaults \"feature\" seed—integer fix R’s random number generator ensure reproducibility. Defaults 123 ...—additional arguments passed stats::kmeans, stats::hclust, mclust::Mclust depending clust_method cluster returns object class feature_clusters essentially named list comprised two elements: \"Data\"—feature_calculations object supplied cluster cluster label appended \"ModelFit\"—raw model object clustering algorithm can easily fit \\(k\\)-means model k = 6 (since theft::simData contains data six different temporal processes): , ’s easy analysis data visualisation:","code":"feature_clusters <- cluster(feature_matrix, k = 6) feature_clusters$Data %>%     dplyr::filter(names %in% c(\"CO_HistogramAMI_even_2_5\",                                 \"DN_OutlierInclude_p_001_mdrmd\")) %>%     tidyr::pivot_wider(id_cols = c(\"id\", \"group\", \"cluster\"),                         names_from = \"names\", values_from = \"values\") %>%     ggplot2::ggplot(ggplot2::aes(x = CO_HistogramAMI_even_2_5,                                   DN_OutlierInclude_p_001_mdrmd,                                   colour = as.factor(cluster))) +     ggplot2::stat_ellipse(ggplot2::aes(fill = as.factor(cluster)), geom = \"polygon\", alpha = 0.2) +     ggplot2::geom_point() +     ggplot2::labs(colour = \"Cluster\") +     ggplot2::guides(fill = \"none\") +     ggplot2::scale_fill_brewer(palette = \"Dark2\") +     ggplot2::scale_colour_brewer(palette = \"Dark2\") +     ggplot2::theme_bw() +     ggplot2::theme(legend.position = \"bottom\",                    panel.grid.minor = ggplot2::element_blank())"},{"path":"https://hendersontrent.github.io/theftdlc/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Trent Henderson. Maintainer, author.","code":""},{"path":"https://hendersontrent.github.io/theftdlc/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Henderson T (2024). theftdlc: Analyse Interpret Time Series Features. R package version 0.1.1, https://hendersontrent.github.io/theftdlc/.","code":"@Manual{,   title = {theftdlc: Analyse and Interpret Time Series Features},   author = {Trent Henderson},   year = {2024},   note = {R package version 0.1.1},   url = {https://hendersontrent.github.io/theftdlc/}, }"},{"path":"https://hendersontrent.github.io/theftdlc/index.html","id":"theftdlc-","dir":"","previous_headings":"","what":"Analyse and Interpret Time Series Features","title":"Analyse and Interpret Time Series Features","text":"Analyse Interpret Time Series Features","code":""},{"path":"https://hendersontrent.github.io/theftdlc/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Analyse and Interpret Time Series Features","text":"can install stable version theftdlc CRAN: can install development version theftdlc GitHub using following:","code":"install.packages(\"theftdlc\") devtools::install_github(\"hendersontrent/theftdlc\")"},{"path":"https://hendersontrent.github.io/theftdlc/index.html","id":"general-purpose","dir":"","previous_headings":"","what":"General purpose","title":"Analyse and Interpret Time Series Features","text":"theft package R facilitates user-friendly access structured analytical workflow extraction time-series features six different feature sets (set user-supplied features): \"catch22\", \"feasts\", \"Kats\", \"tsfeatures\", \"tsfresh\", \"TSFEL\". theftdlc extends feature-based ecosystem providing suite functions analysing, interpreting, visualising time-series features calculated using theft. Functionality including data quality assessments normalisation methods, low dimensional projections (linear nonlinear), data matrix feature distribution visualisations, time-series classification machine learning procedures, statistical hypothesis testing, various statistical graphical tools.  high-level overview theft ecosystem R typically accessed users shown . Many functions options customisation available within packages.","code":""},{"path":"https://hendersontrent.github.io/theftdlc/index.html","id":"whats-in-a-name","dir":"","previous_headings":"General purpose","what":"What’s in a name?","title":"Analyse and Interpret Time Series Features","text":"theftdlc means ‘downloadable content’ (DLC) theft—just like get DLCs expansions video games.","code":""},{"path":"https://hendersontrent.github.io/theftdlc/index.html","id":"quick-tour","dir":"","previous_headings":"","what":"Quick tour","title":"Analyse and Interpret Time Series Features","text":"theft theftdlc combine create intuitive efficient tidy feature-based workflow. example single code chunk calculates features using catch22 custom set mean standard deviation, projects feature space interpretable two-dimensional space using principal components analysis:  example, calculate_features comes theft, project plot generic come theftdlc. Similarly, can perform time-series classification using similar simple workflow compare performance catch22 custom set first two moments distribution: example, classify compare_features come theftdlc. Please see vignette information full functionality packages.","code":"library(dplyr) library(theft) library(theftdlc)  calculate_features(data = theft::simData,                     group_var = \"process\",                     feature_set = \"catch22\",                    features = list(\"mean\" = mean, \"sd\" = sd)) %>%   project(norm_method = \"RobustSigmoid\",           unit_int = TRUE,           low_dim_method = \"PCA\") %>%   plot() calculate_features(data = theft::simData,                     group_var = \"process\",                     feature_set = \"catch22\",                    features = list(\"mean\" = mean, \"sd\" = sd)) %>%   classify(by_set = TRUE,            n_resamples = 5,            use_null = TRUE) %>%   compare_features(by_set = TRUE,                    hypothesis = \"null\") %>%   head() hypothesis   feature_set   metric  set_mean null_mean 1  All features != own null  All features accuracy 0.8400000 0.1688889 2 User-supplied != own null User-supplied accuracy 0.7066667 0.1111111 3       catch22 != own null       catch22 accuracy 0.7066667 0.1600000   t_statistic      p.value 1    9.089132 0.0008124621 2    5.512023 0.0052862976 3    7.363817 0.0018119523"},{"path":"https://hendersontrent.github.io/theftdlc/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Analyse and Interpret Time Series Features","text":"use theft theftdlc work, please cite paper: T. Henderson Ben D. Fulcher. Feature-Based Time-Series Analysis R using theft Package. arXiv, (2022). software:","code":"To cite package 'theft' in publications use:    Trent Henderson (2024). theft: Tools for Handling Extraction of   Features from Time Series. R package version 0.6.1.   https://hendersontrent.github.io/theft/  A BibTeX entry for LaTeX users is    @Manual{,     title = {theft: Tools for Handling Extraction of Features from Time Series},     author = {Trent Henderson},     year = {2024},     note = {R package version 0.6.1},     url = {https://hendersontrent.github.io/theft/},   }   To cite package 'theftdlc' in publications use:    Trent Henderson (2024). theftdlc: Analyse and Interpret Time Series   Features. R package version 0.1.0.   https://hendersontrent.github.io/theftdlc/  A BibTeX entry for LaTeX users is    @Manual{,     title = {theftdlc: Analyse and Interpret Time Series Features},     author = {Trent Henderson},     year = {2024},     note = {R package version 0.1.0},     url = {https://hendersontrent.github.io/theftdlc/},   }"},{"path":"https://hendersontrent.github.io/theftdlc/reference/classify.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit classifiers using time-series features using a resample-based approach and get a fast understanding of performance — classify","title":"Fit classifiers using time-series features using a resample-based approach and get a fast understanding of performance — classify","text":"Fit classifiers using time-series features using resample-based approach get fast understanding performance","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/classify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit classifiers using time-series features using a resample-based approach and get a fast understanding of performance — classify","text":"","code":"classify(   data,   classifier = NULL,   train_size = 0.75,   n_resamples = 30,   by_set = TRUE,   use_null = FALSE,   seed = 123 )  tsfeature_classifier(   data,   classifier = NULL,   train_size = 0.75,   n_resamples = 30,   by_set = TRUE,   use_null = FALSE,   seed = 123 )"},{"path":"https://hendersontrent.github.io/theftdlc/reference/classify.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit classifiers using time-series features using a resample-based approach and get a fast understanding of performance — classify","text":"data feature_calculations object containing raw feature matrix produced theft::calculate_features classifier function specifying classifier fit. function 2 arguments: formula data containing classifier compatible R's predict functionality. Please note classify z-scores data prior modelling using train set's information disabling default scaling function uses recommended. Defaults NULL means following linear SVM fit: classifier = function(formula, data){mod <- e1071::svm(formula, data = data, kernel = \"linear\", scale = FALSE, probability = TRUE)} train_size numeric denoting proportion samples use training set. Defaults 0.75 n_resamples integer denoting number resamples calculate. Defaults 30 by_set Boolean specifying whether compute classifiers feature set. Defaults TRUE. FALSE, function instead find best individually-performing features use_null Boolean whether fit null models class labels shuffled order generate null distribution can compared performance correct class labels. Defaults FALSE seed integer fix R's random number generator ensure reproducibility. Defaults 123","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/classify.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit classifiers using time-series features using a resample-based approach and get a fast understanding of performance — classify","text":"list containing named vector train-test set sizes, data.frame classification performance results","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/classify.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fit classifiers using time-series features using a resample-based approach and get a fast understanding of performance — classify","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/classify.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit classifiers using time-series features using a resample-based approach and get a fast understanding of performance — classify","text":"","code":"library(theft)  features <- theft::calculate_features(theft::simData,   group_var = \"process\",   feature_set = \"catch22\") #> No IDs removed. All value vectors good for feature extraction. #> Running computations for catch22... #> Warning: There was 1 warning in `dplyr::reframe()`. #> ℹ In argument: `Rcatch22::catch22_all(.data$values, catch24 = catch24)`. #> ℹ In group 1: `id = \"Gaussian Noise_1\"`, `group = \"Gaussian Noise\"`. #> Caused by warning: #> ! As of 0.1.14 the feature 'CO_f1ecac' returns a double instead of int #> This warning is displayed once per session. #>  #> Calculations completed for catch22.  classifiers <- classify(features,   by_set = FALSE,   n_resamples = 3) #> Only one set of 'catch22', 'feasts', 'tsfeatures', or 'Kats' with potential duplicates is in your feature data. Exiting and returning original input data. #> Fitting model 1/66 #> Fitting model 2/66 #> Fitting model 3/66 #> Fitting model 4/66 #> Fitting model 5/66 #> Fitting model 6/66 #> Fitting model 7/66 #> Fitting model 8/66 #> Fitting model 9/66 #> Fitting model 10/66 #> Fitting model 11/66 #> Fitting model 12/66 #> Fitting model 13/66 #> Fitting model 14/66 #> Fitting model 15/66 #> Fitting model 16/66 #> Fitting model 17/66 #> Fitting model 18/66 #> Fitting model 19/66 #> Fitting model 20/66 #> Fitting model 21/66 #> Fitting model 22/66 #> Fitting model 23/66 #> Fitting model 24/66 #> Fitting model 25/66 #> Fitting model 26/66 #> Fitting model 27/66 #> Fitting model 28/66 #> Fitting model 29/66 #> Fitting model 30/66 #> Fitting model 31/66 #> Fitting model 32/66 #> Fitting model 33/66 #> Fitting model 34/66 #> Fitting model 35/66 #> Fitting model 36/66 #> Fitting model 37/66 #> Fitting model 38/66 #> Fitting model 39/66 #> Fitting model 40/66 #> Fitting model 41/66 #> Fitting model 42/66 #> Fitting model 43/66 #> Fitting model 44/66 #> Fitting model 45/66 #> Fitting model 46/66 #> Fitting model 47/66 #> Fitting model 48/66 #> Fitting model 49/66 #> Fitting model 50/66 #> Fitting model 51/66 #> Fitting model 52/66 #> Fitting model 53/66 #> Fitting model 54/66 #> Fitting model 55/66 #> Fitting model 56/66 #> Fitting model 57/66 #> Fitting model 58/66 #> Fitting model 59/66 #> Fitting model 60/66 #> Fitting model 61/66 #> Fitting model 62/66 #> Fitting model 63/66 #> Fitting model 64/66 #> Fitting model 65/66 #> Fitting model 66/66"},{"path":"https://hendersontrent.github.io/theftdlc/reference/cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform cluster analysis of time series using their feature vectors — cluster","title":"Perform cluster analysis of time series using their feature vectors — cluster","text":"Perform cluster analysis time series using feature vectors","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform cluster analysis of time series using their feature vectors — cluster","text":"","code":"cluster(   data,   norm_method = c(\"zScore\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\", \"MaxAbs\"),   unit_int = FALSE,   clust_method = c(\"kmeans\", \"hclust\", \"mclust\"),   k = 2,   features = NULL,   na_removal = c(\"feature\", \"sample\"),   seed = 123,   ... )"},{"path":"https://hendersontrent.github.io/theftdlc/reference/cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform cluster analysis of time series using their feature vectors — cluster","text":"data feature_calculations object containing raw feature matrix produced theft::calculate_features norm_method character denoting rescaling/normalising method apply. Can one \"zScore\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\", \"MaxAbs\". Defaults \"zScore\" unit_int Boolean whether rescale unit interval [0,1] applying normalisation method. Defaults FALSE clust_method character specifying clustering algorithm use. Can one \"kmeans\" k-means clustering, \"hclust\" hierarchical clustering, \"mclust\" Gaussian mixture model clustering. Defaults \"kMeans\" k integer denoting number clusters extract. Defaults 2 features character vector denoting names time-series features use clustering algorithm. Defaults NULL feature filtering usage entire feature matrix na_removal character defining way deal NAs produced feature calculation. Can one \"feature\" \"sample\". \"feature\" removes features produced NAs sample, keeping number samples . \"sample\" omits samples produced least one NA. Defaults \"feature\" seed integer fix R's random number generator ensure reproducibility. Defaults 123 ... arguments passed stats::kmeans stats::hclust, mclust::Mclust depending selection clust_method","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform cluster analysis of time series using their feature vectors — cluster","text":"object class feature_cluster containing clustering algorithm tidy version clusters joined input dataset ready analysis","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/cluster.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Perform cluster analysis of time series using their feature vectors — cluster","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/cluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform cluster analysis of time series using their feature vectors — cluster","text":"","code":"library(theft)  features <- theft::calculate_features(theft::simData,   group_var = \"process\",   feature_set = \"catch22\") #> No IDs removed. All value vectors good for feature extraction. #> Running computations for catch22... #>  #> Calculations completed for catch22.  clusts <- cluster(features,   k = 6)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/compare_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Conduct statistical testing on time-series feature classification performance to identify top features or compare entire sets — compare_features","title":"Conduct statistical testing on time-series feature classification performance to identify top features or compare entire sets — compare_features","text":"Conduct statistical testing time-series feature classification performance identify top features compare entire sets","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/compare_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conduct statistical testing on time-series feature classification performance to identify top features or compare entire sets — compare_features","text":"","code":"compare_features(   data,   metric = c(\"accuracy\", \"precision\", \"recall\", \"f1\"),   by_set = TRUE,   hypothesis = c(\"null\", \"pairwise\"),   p_adj = c(\"none\", \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"BY\", \"fdr\") )"},{"path":"https://hendersontrent.github.io/theftdlc/reference/compare_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conduct statistical testing on time-series feature classification performance to identify top features or compare entire sets — compare_features","text":"data list object containing classification outputs produce tsfeature_classifier metric character denoting classification performance metric use statistical testing. Can one \"accuracy\", \"precision\", \"recall\", \"f1\". Defaults \"accuracy\" by_set Boolean specifying whether want compare feature sets (TRUE) individual features (FALSE). Defaults TRUE contingent whether computed set tsfeature_classifier hypothesis character denoting whether p-values calculated feature set feature (depending by_set argument) individually relative null use_null = TRUE tsfeature_classifier \"null\", whether pairwise comparisons set feature conducted main model fits \"pairwise\". Defaults \"null\" p_adj character denoting adjustment made p-values multiple comparisons. valid argument stats::p.adjust. Defaults \"none\" adjustment. \"holm\" recommended starting point adjustments","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/compare_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conduct statistical testing on time-series feature classification performance to identify top features or compare entire sets — compare_features","text":"data.frame containing results","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/compare_features.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Conduct statistical testing on time-series feature classification performance to identify top features or compare entire sets — compare_features","text":"Henderson, T., Bryant, . G., Fulcher, B. D. Never Dull Moment: Distributional Properties Baseline Time-Series Classification. 27th Pacific-Asia Conference Knowledge Discovery Data Mining, (2023).","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/compare_features.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Conduct statistical testing on time-series feature classification performance to identify top features or compare entire sets — compare_features","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/compare_features.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conduct statistical testing on time-series feature classification performance to identify top features or compare entire sets — compare_features","text":"","code":"library(theft)  features <- theft::calculate_features(theft::simData,   group_var = \"process\",   feature_set = NULL,   features = list(\"mean\" = mean, \"sd\" = sd)) #> No IDs removed. All value vectors good for feature extraction. #> Running computations for user-supplied features... #>  #> Calculations completed for user-supplied features.  classifiers <- classify(features,                         by_set = FALSE,                         n_resamples = 3) #> Only one set of 'catch22', 'feasts', 'tsfeatures', or 'Kats' with potential duplicates is in your feature data. Exiting and returning original input data. #> Fitting model 1/6 #> Fitting model 2/6 #> Fitting model 3/6 #> Fitting model 4/6 #> Fitting model 5/6 #> Fitting model 6/6  compare_features(classifiers,                  by_set = FALSE,                  hypothesis = \"pairwise\") #> Calculating comparison 1/1 #>                               hypothesis            names_a          names_b #> 1 User-supplied_mean != User-supplied_sd User-supplied_mean User-supplied_sd #>     metric names_a_mean names_b_mean t_statistic  p.value #> 1 accuracy    0.1851852    0.6148148   -8.043153 1.984892"},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_duplicates.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove duplicate features that exist in multiple feature sets and retain a reproducible random selection of one of them — filter_duplicates","title":"Remove duplicate features that exist in multiple feature sets and retain a reproducible random selection of one of them — filter_duplicates","text":"Remove duplicate features exist multiple feature sets retain reproducible random selection one ","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_duplicates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove duplicate features that exist in multiple feature sets and retain a reproducible random selection of one of them — filter_duplicates","text":"","code":"filter_duplicates(data, preference = NULL, seed = 123)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_duplicates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove duplicate features that exist in multiple feature sets and retain a reproducible random selection of one of them — filter_duplicates","text":"data feature_calculations object containing raw feature matrix produced calculate_features preference deprecated. use seed integer denoting fix R's pseudo-random number generator ensure selections reproducible. Defaults 123","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_duplicates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove duplicate features that exist in multiple feature sets and retain a reproducible random selection of one of them — filter_duplicates","text":"feature_calculations object containing filtered feature data","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_duplicates.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Remove duplicate features that exist in multiple feature sets and retain a reproducible random selection of one of them — filter_duplicates","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_good_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter resample data sets according to good feature list — filter_good_features","title":"Filter resample data sets according to good feature list — filter_good_features","text":"Filter resample data sets according good feature list","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_good_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter resample data sets according to good feature list — filter_good_features","text":"","code":"filter_good_features(data, x, good_features)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_good_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter resample data sets according to good feature list — filter_good_features","text":"data list \"Train\" \"Test\" data x integer denoting resample index operate good_features character vector good features keep","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_good_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter resample data sets according to good feature list — filter_good_features","text":"list filtered train test data","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/filter_good_features.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Filter resample data sets according to good feature list — filter_good_features","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/find_good_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to find features in both train and test set that are ","title":"Helper function to find features in both train and test set that are ","text":"Helper function find features train test set \"good\"","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/find_good_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to find features in both train and test set that are ","text":"","code":"find_good_features(data, x)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/find_good_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to find features in both train and test set that are ","text":"data list \"Train\" \"Test\" data x integer denoting resample index operate ","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/find_good_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to find features in both train and test set that are ","text":"character vector \"good\" feature names","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/find_good_features.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Helper function to find features in both train and test set that are ","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/fit_models.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit classification model and compute key metrics — fit_models","title":"Fit classification model and compute key metrics — fit_models","text":"Fit classification model compute key metrics","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/fit_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit classification model and compute key metrics — fit_models","text":"","code":"fit_models(data, iter_data, row_id, is_null_run = FALSE, classifier)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/fit_models.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit classification model and compute key metrics — fit_models","text":"data list containing train test sets iter_data data.frame containing values iterate seed either feature name set name row_id integer denoting row ID iter_data filter is_null_run Boolean whether calculation null model. Defaults FALSE classifier function specifying classifier fit. function 2 arguments: formula data. Please note tsfeature_classifier z-scores data prior modelling using train set's information disabling default scaling function uses recommended.","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/fit_models.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit classification model and compute key metrics — fit_models","text":"data.frame classification results","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/fit_models.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fit classification model and compute key metrics — fit_models","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/get_rescale_vals.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate central tendency and spread values for all numeric columns in a dataset — get_rescale_vals","title":"Calculate central tendency and spread values for all numeric columns in a dataset — get_rescale_vals","text":"Calculate central tendency spread values numeric columns dataset","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/get_rescale_vals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate central tendency and spread values for all numeric columns in a dataset — get_rescale_vals","text":"","code":"get_rescale_vals(data)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/get_rescale_vals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate central tendency and spread values for all numeric columns in a dataset — get_rescale_vals","text":"data data.frame containing data normalise","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/get_rescale_vals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate central tendency and spread values for all numeric columns in a dataset — get_rescale_vals","text":"list central tendency spread values","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/get_rescale_vals.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate central tendency and spread values for all numeric columns in a dataset — get_rescale_vals","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/interval.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate interval summaries with a measure of central tendency of classification results — interval","title":"Calculate interval summaries with a measure of central tendency of classification results — interval","text":"Calculate interval summaries measure central tendency classification results","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/interval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate interval summaries with a measure of central tendency of classification results — interval","text":"","code":"interval(   data,   metric = c(\"accuracy\", \"precision\", \"recall\", \"f1\"),   by_set = TRUE,   type = c(\"sd\", \"qt\", \"quantile\"),   interval = NULL,   model_type = c(\"main\", \"null\") )  calculate_interval(   data,   metric = c(\"accuracy\", \"precision\", \"recall\", \"f1\"),   by_set = TRUE,   type = c(\"sd\", \"qt\", \"quantile\"),   interval = NULL,   model_type = c(\"main\", \"null\") )"},{"path":"https://hendersontrent.github.io/theftdlc/reference/interval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate interval summaries with a measure of central tendency of classification results — interval","text":"data list object containing classification outputs produce tsfeature_classifier metric character denoting classification performance metric calculate intervals . Can one \"accuracy\", \"precision\", \"recall\", \"f1\". Defaults \"accuracy\" by_set Boolean specifying whether compute intervals feature set. Defaults TRUE. FALSE, function instead calculate intervals feature type character denoting whether calculate +/- SD interval \"sd\", confidence interval based t-distribution \"qt\", based quantile \"quantile\". Defaults \"sd\" interval numeric scalar denoting width interval calculate. Defaults 1 type = \"sd\" produce +/- 1 SD interval. Defaults 0.95 type = \"qt\" type = \"quantile\" 95 per cent interval model_type character denoting whether calculate intervals main models \"main\" null models \"null\" use_null argument using tsfeature_classifier use_null = TRUE. Defaults \"main\"","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/interval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate interval summaries with a measure of central tendency of classification results — interval","text":"data.frame containing results","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/interval.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate interval summaries with a measure of central tendency of classification results — interval","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/interval.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate interval summaries with a measure of central tendency of classification results — interval","text":"","code":"library(theft)  features <- theft::calculate_features(theft::simData,   group_var = \"process\",   feature_set = NULL,   features = list(\"mean\" = mean, \"sd\" = sd)) #> No IDs removed. All value vectors good for feature extraction. #> Running computations for user-supplied features... #>  #> Calculations completed for user-supplied features.  classifiers <- classify(features,   by_set = FALSE,   n_resamples = 3) #> Only one set of 'catch22', 'feasts', 'tsfeatures', or 'Kats' with potential duplicates is in your feature data. Exiting and returning original input data. #> Fitting model 1/6 #> Fitting model 2/6 #> Fitting model 3/6 #> Fitting model 4/6 #> Fitting model 5/6 #> Fitting model 6/6  interval(classifiers,   by_set = FALSE,   type = \"sd\",   interval = 1) #>                names     .mean    .lower    .upper #> 1 User-supplied_mean 0.1851852 0.1723552 0.1980152 #> 2   User-supplied_sd 0.6148148 0.5634948 0.6661348"},{"path":"https://hendersontrent.github.io/theftdlc/reference/make_title.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function for converting to title case — make_title","title":"Helper function for converting to title case — make_title","text":"Helper function converting title case","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/make_title.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function for converting to title case — make_title","text":"","code":"make_title(x)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/make_title.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function for converting to title case — make_title","text":"x character vector","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/make_title.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function for converting to title case — make_title","text":"character vector","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/make_title.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Helper function for converting to title case — make_title","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_calculations.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce a plot for a feature_calculations object — plot.feature_calculations","title":"Produce a plot for a feature_calculations object — plot.feature_calculations","text":"Produce plot feature_calculations object","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_calculations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce a plot for a feature_calculations object — plot.feature_calculations","text":"","code":"# S3 method for feature_calculations plot(   x,   type = c(\"quality\", \"matrix\", \"cor\", \"violin\"),   norm_method = c(\"zScore\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\", \"MaxAbs\"),   unit_int = FALSE,   clust_method = c(\"average\", \"ward.D\", \"ward.D2\", \"single\", \"complete\", \"mcquitty\",     \"median\", \"centroid\"),   cor_method = c(\"pearson\", \"spearman\"),   feature_names = NULL,   ... )"},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_calculations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce a plot for a feature_calculations object — plot.feature_calculations","text":"x feature_calculations object containing raw feature matrix produced theft::calculate_features type character specifying type plot draw. Defaults \"quality\" norm_method character specifying rescaling/normalising method apply type = \"matrix\" type = \"cor\". Can one \"zScore\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\", \"MaxAbs\". Defaults \"zScore\" unit_int Boolean whether rescale unit interval [0,1] applying normalisation method. Defaults FALSE clust_method character specifying hierarchical clustering method use type = \"matrix\" type = \"cor\". Defaults \"average\" cor_method character specifying correlation method use type = \"cor\". Defaults \"pearson\" feature_names character vector denoting name features plot type = \"violin\". Defaults NULL ... Arguments passed ggplot2::geom_bar type = \"quality\", ggplot2::geom_raster type = \"matrix\", ggplot2::geom_raster type = \"cor\", ggplot2::geom_point type = \"violin\"","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_calculations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produce a plot for a feature_calculations object — plot.feature_calculations","text":"object class ggplot contains graphic","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_calculations.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Produce a plot for a feature_calculations object — plot.feature_calculations","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_projection.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce a plot for a feature_projection object — plot.feature_projection","title":"Produce a plot for a feature_projection object — plot.feature_projection","text":"Produce plot feature_projection object","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_projection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce a plot for a feature_projection object — plot.feature_projection","text":"","code":"# S3 method for feature_projection plot(x, show_covariance = TRUE, ...)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_projection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce a plot for a feature_projection object — plot.feature_projection","text":"x feature_projection object containing two-dimensional embedding calculated project show_covariance Boolean specifying whether covariance ellipses shown plot. Defaults TRUE ... Arguments passed methods","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_projection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produce a plot for a feature_projection object — plot.feature_projection","text":"object class ggplot contains graphic","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/plot.feature_projection.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Produce a plot for a feature_projection object — plot.feature_projection","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/project.html","id":null,"dir":"Reference","previous_headings":"","what":"Project a feature matrix into a two-dimensional representation using PCA, MDS, t-SNE, or UMAP ready for plotting — project","title":"Project a feature matrix into a two-dimensional representation using PCA, MDS, t-SNE, or UMAP ready for plotting — project","text":"Project feature matrix two-dimensional representation using PCA, MDS, t-SNE, UMAP ready plotting","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/project.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project a feature matrix into a two-dimensional representation using PCA, MDS, t-SNE, or UMAP ready for plotting — project","text":"","code":"project(   data,   norm_method = c(\"zScore\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\", \"MaxAbs\"),   unit_int = FALSE,   low_dim_method = c(\"PCA\", \"tSNE\", \"ClassicalMDS\", \"KruskalMDS\", \"SammonMDS\", \"UMAP\"),   na_removal = c(\"feature\", \"sample\"),   seed = 123,   ... )  reduce_dims(   data,   norm_method = c(\"zScore\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\", \"MaxAbs\"),   unit_int = FALSE,   low_dim_method = c(\"PCA\", \"tSNE\", \"ClassicalMDS\", \"KruskalMDS\", \"SammonMDS\", \"UMAP\"),   na_removal = c(\"feature\", \"sample\"),   seed = 123,   ... )"},{"path":"https://hendersontrent.github.io/theftdlc/reference/project.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project a feature matrix into a two-dimensional representation using PCA, MDS, t-SNE, or UMAP ready for plotting — project","text":"data feature_calculations object containing raw feature matrix produced theft::calculate_features norm_method character denoting rescaling/normalising method apply. Can one \"zScore\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\", \"MaxAbs\". Defaults \"zScore\" unit_int Boolean whether rescale unit interval [0,1] applying normalisation method. Defaults FALSE low_dim_method character specifying low dimensional embedding method use. Can one \"PCA\", \"tSNE\", \"ClassicalMDS\", \"KruskalMDS\", \"SammonMDS\", \"UMAP\". Defaults \"PCA\" na_removal character defining way deal NAs produced feature calculation. Can one \"feature\" \"sample\". \"feature\" removes features produced NAs sample, keeping number samples . \"sample\" omits samples produced least one NA. Defaults \"feature\" seed integer fix R's random number generator ensure reproducibility. Defaults 123 ... arguments passed stats::prcomp Rtsne::Rtsne, stats::cmdscale, MASS::isoMDS, MASS::sammon, umap::umap depending selection low_dim_method","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/project.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Project a feature matrix into a two-dimensional representation using PCA, MDS, t-SNE, or UMAP ready for plotting — project","text":"object class feature_projection named list containing feature_calculations data supplied function, wide matrix filtered data, tidy data.frame projected 2-D data, model fit object","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/project.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Project a feature matrix into a two-dimensional representation using PCA, MDS, t-SNE, or UMAP ready for plotting — project","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/project.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Project a feature matrix into a two-dimensional representation using PCA, MDS, t-SNE, or UMAP ready for plotting — project","text":"","code":"# \\donttest{  library(theft)  features <- theft::calculate_features(theft::simData,   group_var = \"process\",   feature_set = \"catch22\") #> No IDs removed. All value vectors good for feature extraction. #> Running computations for catch22... #>  #> Calculations completed for catch22.  pca <- project(features,   norm_method = \"zScore\",   low_dim_method = \"PCA\") # }"},{"path":"https://hendersontrent.github.io/theftdlc/reference/resample_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to create a resampled dataset — resample_data","title":"Helper function to create a resampled dataset — resample_data","text":"Helper function create resampled dataset","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/resample_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to create a resampled dataset — resample_data","text":"","code":"resample_data(data, train_rows, test_rows, train_groups, test_groups, seed)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/resample_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to create a resampled dataset — resample_data","text":"data data.frame containing time-series features train_rows integer denoting number cases train set test_rows integer denoting number cases test set train_groups data.frame containing proportions class original train split test_groups data.frame containing proportions class original test split seed integer denoting fixed value R's pseudorandom number generator","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/resample_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to create a resampled dataset — resample_data","text":"list containing new train test data","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/resample_data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Helper function to create a resampled dataset — resample_data","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/rescale_zscore.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate z-score for all columns in a dataset using train set central tendency and spread — rescale_zscore","title":"Calculate z-score for all columns in a dataset using train set central tendency and spread — rescale_zscore","text":"Calculate z-score columns dataset using train set central tendency spread","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/rescale_zscore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate z-score for all columns in a dataset using train set central tendency and spread — rescale_zscore","text":"","code":"rescale_zscore(data, rescalers)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/rescale_zscore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate z-score for all columns in a dataset using train set central tendency and spread — rescale_zscore","text":"data data.frame containing data normalise rescalers list containing central tendency spread values train set","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/rescale_zscore.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate z-score for all columns in a dataset using train set central tendency and spread — rescale_zscore","text":"data.frame rescaled data","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/rescale_zscore.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate z-score for all columns in a dataset using train set central tendency and spread — rescale_zscore","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/select_stat_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to select only the relevant columns for statistical testing — select_stat_cols","title":"Helper function to select only the relevant columns for statistical testing — select_stat_cols","text":"Helper function select relevant columns statistical testing","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/select_stat_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to select only the relevant columns for statistical testing — select_stat_cols","text":"","code":"select_stat_cols(data, by_set, metric, hypothesis)"},{"path":"https://hendersontrent.github.io/theftdlc/reference/select_stat_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to select only the relevant columns for statistical testing — select_stat_cols","text":"data data.frame classification accuracy results by_set Boolean specifying whether want compare feature sets (TRUE) individual features (FALSE). metric character denoting classification performance metric use statistical testing. Can one \"accuracy\", \"precision\", \"recall\", \"f1\". Defaults \"accuracy\" hypothesis character denoting whether p-values calculated feature set feature (depending by_set argument) individually relative null use_null = TRUE tsfeature_classifier \"null\", whether pairwise comparisons set feature conducted main model fits \"pairwise\".","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/select_stat_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to select only the relevant columns for statistical testing — select_stat_cols","text":"object class data.frame","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/select_stat_cols.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Helper function to select only the relevant columns for statistical testing — select_stat_cols","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/stat_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate p-values for feature sets or features relative to an empirical null or each other using resampled t-tests — stat_test","title":"Calculate p-values for feature sets or features relative to an empirical null or each other using resampled t-tests — stat_test","text":"Calculate p-values feature sets features relative empirical null using resampled t-tests","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/stat_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate p-values for feature sets or features relative to an empirical null or each other using resampled t-tests — stat_test","text":"","code":"stat_test(   data,   iter_data,   row_id,   by_set = FALSE,   hypothesis,   metric,   train_test_sizes,   n_resamples )"},{"path":"https://hendersontrent.github.io/theftdlc/reference/stat_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate p-values for feature sets or features relative to an empirical null or each other using resampled t-tests — stat_test","text":"data data.frame raw classification accuracy results iter_data data.frame containing values iterate seed either feature name set name row_id integer denoting row ID iter_data filter by_set Boolean specifying whether want compare feature sets (TRUE) individual features (FALSE). hypothesis character denoting whether p-values calculated feature set feature (depending by_set argument) individually relative null use_null = TRUE tsfeature_classifier \"null\", whether pairwise comparisons set feature conducted main model fits \"pairwise\". metric character denoting classification performance metric use statistical testing. Can one \"accuracy\", \"precision\", \"recall\", \"f1\". Defaults \"accuracy\" train_test_sizes integer vector containing train test set sample sizes n_resamples integer denoting number resamples calculated","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/stat_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate p-values for feature sets or features relative to an empirical null or each other using resampled t-tests — stat_test","text":"object class data.frame","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/stat_test.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate p-values for feature sets or features relative to an empirical null or each other using resampled t-tests — stat_test","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theftdlc/reference/theftdlc.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyse and Interpret Time Series Features — theftdlc","title":"Analyse and Interpret Time Series Features — theftdlc","text":"Analyse Interpret Time Series Features","code":""}]
